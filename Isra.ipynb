{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Isra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "10qbfEtglgTP3fe0tMLIknVk5fs-dFhUW",
      "authorship_tag": "ABX9TyMJal9hVT7vJo1tRhFRFEnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelMelMon/CustomTrain-MobileNetV2/blob/master/Isra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0X1u6MqxlHb"
      },
      "source": [
        "# Train your custom MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7g80Odcb8AP"
      },
      "source": [
        "See the original Github repository [here](https://github.com/IsraelMelMon/CustomTrain-MobileNetV2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2MsbU2Mx8JN"
      },
      "source": [
        "First, you must be signed-in to a [Google Drive](https://drive.google.com) account. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI7CoEBm5A6Y"
      },
      "source": [
        "Have a folder in your Google Drive named \"**mobilenet2/classes**\" that contains all the training images. \n",
        " >/content/drive/My Drive/mobilenet2/classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mak2DW605R2Z"
      },
      "source": [
        "Each class should be a sub-folder contained in the main training folder. \n",
        "An example with two classes is shown (although N different classes are supported):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTUrEGvk0z69"
      },
      "source": [
        "*/content/drive/My Drive/mobilenet2/*\n",
        "```sh\n",
        "├── mobilenet2\n",
        "  ├── example (can be downloaded from the Github)\n",
        "  ├── trainmobilenetv2 (can be downloaded from Github)\n",
        "  ├── classes\n",
        "    ├── class_A\n",
        "       ├── class_A_1.png\n",
        "       ├── class_A_2.png\n",
        "       ├── class_A_3.png\n",
        "       ├── ...\n",
        "       └── class_A_30.png\n",
        "    └── class_B\n",
        "        ├── class_B_1.png\n",
        "        ├── class_B_2.png\n",
        "        ├── class_B_3.png\n",
        "        ├── ...\n",
        "        └── class_B_30.png\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNYmE5eNaCpL"
      },
      "source": [
        "**Caution: Each image should contain the respective class' name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQXCfwJ5chn"
      },
      "source": [
        "Next, we give Google Colab permission to access the files in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXR6TA_HCxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d9adf1-87dc-4aca-c341-ed8ad5380f43"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XgcnMvLAH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fdc5da-2554-46ac-eab8-63bb9ef21761"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDU5QO3K-0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583b2de4-f4d6-4cbb-bd73-70da0098b38e"
      },
      "source": [
        "!git clone https://github.com/IsraelMelMon/CustomTrain-MobileNetV2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CustomTrain-MobileNetV2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 90\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JRLSNiLEsk"
      },
      "source": [
        "cd CustomTrain-MobileNetV2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFi_NwK55rvq"
      },
      "source": [
        "Let's run the initial configuration file. The first argument is the absolute path to the training images folder, and the second argument is the number of epochs (default 50).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-8hY67Nxko5"
      },
      "source": [
        "!python3 '/content/CustomTrain-MobileNetV2/auto_setup.py' --path '/content/drive/MyDrive/DATASETS/HEB/TOP_10_CLASSES_JAN_27_2020/' "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJ966MdxcPv"
      },
      "source": [
        "Now we train our MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqbIBPp0kye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0defd124-e547-45f4-cff0-d415efc8b9f6"
      },
      "source": [
        "!python3 '/content/CustomTrain-MobileNetV2/scripts/train.py' --csv_path '/content/config_files/data.csv' --data_config_path '/content/config_files/data_config.yaml' --training_config_path '/content/config_files/training_config.yaml'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['pera_asiatica_1.png', 'pera_asiatica_10.png', 'pera_asiatica_100.png', 'pera_asiatica_101.png', 'pera_asiatica_102.png', 'pera_asiatica_103.png', 'pera_asiatica_104.png', 'pera_asiatica_105.png', 'pera_asiatica_106.png', 'pera_asiatica_107.png', 'pera_asiatica_108.png', 'pera_asiatica_109.png', 'pera_asiatica_11.png', 'pera_asiatica_110.png', 'pera_asiatica_111.png', 'pera_asiatica_112.png', 'pera_asiatica_113.png', 'pera_asiatica_114.png', 'pera_asiatica_115.png', 'pera_asiatica_116.png', 'pera_asiatica_117.png', 'pera_asiatica_118.png', 'pera_asiatica_119.png', 'pera_asiatica_12.png', 'pera_asiatica_120.png', 'pera_asiatica_121.png', 'pera_asiatica_122.png', 'pera_asiatica_123.png', 'pera_asiatica_124.png', 'pera_asiatica_125.png', 'pera_asiatica_126.png', 'pera_asiatica_127.png', 'pera_asiatica_128.png', 'pera_asiatica_129.png', 'pera_asiatica_13.png', 'pera_asiatica_130.png', 'pera_asiatica_131.png', 'pera_asiatica_132.png', 'pera_asiatica_133.png', 'pera_asiatica_134.png', 'pera_asiatica_135.png', 'pera_asiatica_136.png', 'pera_asiatica_137.png', 'pera_asiatica_138.png', 'pera_asiatica_139.png', 'pera_asiatica_14.png', 'pera_asiatica_140.png', 'pera_asiatica_141.png', 'pera_asiatica_142.png', 'pera_asiatica_143.png', 'pera_asiatica_144.png', 'pera_asiatica_145.png', 'pera_asiatica_146.png', 'pera_asiatica_147.png', 'pera_asiatica_148.png', 'pera_asiatica_149.png', 'pera_asiatica_15.png', 'pera_asiatica_150.png', 'pera_asiatica_151.png', 'pera_asiatica_152.png', 'pera_asiatica_153.png', 'pera_asiatica_154.png', 'pera_asiatica_155.png', 'pera_asiatica_156.png', 'pera_asiatica_157.png', 'pera_asiatica_158.png', 'pera_asiatica_159.png', 'pera_asiatica_16.png', 'pera_asiatica_160.png', 'pera_asiatica_161.png', 'pera_asiatica_162.png', 'pera_asiatica_163.png', 'pera_asiatica_164.png', 'pera_asiatica_165.png', 'pera_asiatica_166.png', 'pera_asiatica_167.png', 'pera_asiatica_168.png', 'pera_asiatica_169.png', 'pera_asiatica_17.png', 'pera_asiatica_170.png', 'pera_asiatica_171.png', 'pera_asiatica_172.png', 'pera_asiatica_173.png', 'pera_asiatica_174.png', 'pera_asiatica_175.png', 'pera_asiatica_176.png', 'pera_asiatica_177.png', 'pera_asiatica_178.png', 'pera_asiatica_179.png', 'pera_asiatica_18.png', 'pera_asiatica_180.png', 'pera_asiatica_181.png', 'pera_asiatica_182.png', 'pera_asiatica_183.png', 'pera_asiatica_184.png', 'pera_asiatica_185.png', 'pera_asiatica_186.png', 'pera_asiatica_187.png', 'pera_asiatica_188.png', 'pera_asiatica_189.png', 'pera_asiatica_19.png', 'pera_asiatica_190.png', 'pera_asiatica_191.png', 'pera_asiatica_192.png', 'pera_asiatica_193.png', 'pera_asiatica_194.png', 'pera_asiatica_195.png', 'pera_asiatica_196.png', 'pera_asiatica_197.png', 'pera_asiatica_198.png', 'pera_asiatica_199.png', 'pera_asiatica_2.png', 'pera_asiatica_20.png', 'pera_asiatica_200.png', 'pera_asiatica_201.png', 'pera_asiatica_202.png', 'pera_asiatica_203.png', 'pera_asiatica_204.png', 'pera_asiatica_205.png', 'pera_asiatica_206.png', 'pera_asiatica_207.png', 'pera_asiatica_208.png', 'pera_asiatica_209.png', 'pera_asiatica_21.png', 'pera_asiatica_210.png', 'pera_asiatica_211.png', 'pera_asiatica_212.png', 'pera_asiatica_213.png', 'pera_asiatica_214.png', 'pera_asiatica_215.png', 'pera_asiatica_216.png', 'pera_asiatica_217.png', 'pera_asiatica_218.png', 'pera_asiatica_219.png', 'pera_asiatica_22.png', 'pera_asiatica_220.png', 'pera_asiatica_221.png', 'pera_asiatica_222.png', 'pera_asiatica_223.png', 'pera_asiatica_224.png', 'pera_asiatica_225.png', 'pera_asiatica_226.png', 'pera_asiatica_227.png', 'pera_asiatica_228.png', 'pera_asiatica_229.png', 'pera_asiatica_23.png', 'pera_asiatica_230.png', 'pera_asiatica_231.png', 'pera_asiatica_232.png', 'pera_asiatica_233.png', 'pera_asiatica_234.png', 'pera_asiatica_235.png', 'pera_asiatica_236.png', 'pera_asiatica_237.png', 'pera_asiatica_238.png', 'pera_asiatica_239.png', 'pera_asiatica_24.png', 'pera_asiatica_240.png', 'pera_asiatica_241.png', 'pera_asiatica_242.png', 'pera_asiatica_243.png', 'pera_asiatica_244.png', 'pera_asiatica_245.png', 'pera_asiatica_246.png', 'pera_asiatica_247.png', 'pera_asiatica_248.png', 'pera_asiatica_249.png', 'pera_asiatica_25.png', 'pera_asiatica_250.png', 'pera_asiatica_251.png', 'pera_asiatica_252.png', 'pera_asiatica_253.png', 'pera_asiatica_254.png', 'pera_asiatica_255.png', 'pera_asiatica_256.png', 'pera_asiatica_257.png', 'pera_asiatica_258.png', 'pera_asiatica_259.png', 'pera_asiatica_26.png', 'pera_asiatica_260.png', 'pera_asiatica_261.png', 'pera_asiatica_262.png', 'pera_asiatica_263.png', 'pera_asiatica_264.png', 'pera_asiatica_265.png', 'pera_asiatica_266.png', 'pera_asiatica_267.png', 'pera_asiatica_268.png', 'pera_asiatica_269.png', 'pera_asiatica_27.png', 'pera_asiatica_270.png', 'pera_asiatica_271.png', 'pera_asiatica_272.png', 'pera_asiatica_273.png', 'pera_asiatica_274.png', 'pera_asiatica_275.png', 'pera_asiatica_276.png', 'pera_asiatica_277.png', 'pera_asiatica_278.png', 'pera_asiatica_279.png', 'pera_asiatica_28.png', 'pera_asiatica_280.png', 'pera_asiatica_281.png', 'pera_asiatica_282.png', 'pera_asiatica_283.png', 'pera_asiatica_284.png', 'pera_asiatica_285.png', 'pera_asiatica_286.png', 'pera_asiatica_287.png', 'pera_asiatica_288.png', 'pera_asiatica_289.png', 'pera_asiatica_29.png', 'pera_asiatica_290.png', 'pera_asiatica_291.png', 'pera_asiatica_292.png', 'pera_asiatica_293.png', 'pera_asiatica_294.png', 'pera_asiatica_295.png', 'pera_asiatica_296.png', 'pera_asiatica_297.png', 'pera_asiatica_298.png', 'pera_asiatica_299.png', 'pera_asiatica_3.png', 'pera_asiatica_30.png', 'pera_asiatica_300.png', 'pera_asiatica_31.png', 'pera_asiatica_32.png', 'pera_asiatica_33.png', 'pera_asiatica_34.png', 'pera_asiatica_35.png', 'pera_asiatica_36.png', 'pera_asiatica_37.png', 'pera_asiatica_38.png', 'pera_asiatica_39.png', 'pera_asiatica_4.png', 'pera_asiatica_40.png', 'pera_asiatica_41.png', 'pera_asiatica_42.png', 'pera_asiatica_43.png', 'pera_asiatica_44.png', 'pera_asiatica_45.png', 'pera_asiatica_46.png', 'pera_asiatica_47.png', 'pera_asiatica_48.png', 'pera_asiatica_49.png', 'pera_asiatica_5.png', 'pera_asiatica_50.png', 'pera_asiatica_51.png', 'pera_asiatica_52.png', 'pera_asiatica_53.png', 'pera_asiatica_54.png', 'pera_asiatica_55.png', 'pera_asiatica_56.png', 'pera_asiatica_57.png', 'pera_asiatica_58.png', 'pera_asiatica_59.png', 'pera_asiatica_6.png', 'pera_asiatica_60.png', 'pera_asiatica_61.png', 'pera_asiatica_62.png', 'pera_asiatica_63.png', 'pera_asiatica_64.png', 'pera_asiatica_65.png', 'pera_asiatica_66.png', 'pera_asiatica_67.png', 'pera_asiatica_68.png', 'pera_asiatica_69.png', 'pera_asiatica_7.png', 'pera_asiatica_70.png', 'pera_asiatica_71.png', 'pera_asiatica_72.png', 'pera_asiatica_73.png', 'pera_asiatica_74.png', 'pera_asiatica_75.png', 'pera_asiatica_76.png', 'pera_asiatica_77.png', 'pera_asiatica_78.png', 'pera_asiatica_79.png', 'pera_asiatica_8.png', 'pera_asiatica_80.png', 'pera_asiatica_81.png', 'pera_asiatica_82.png', 'pera_asiatica_83.png', 'pera_asiatica_84.png', 'pera_asiatica_85.png', 'pera_asiatica_86.png', 'pera_asiatica_87.png', 'pera_asiatica_88.png', 'pera_asiatica_89.png', 'pera_asiatica_9.png', 'pera_asiatica_90.png', 'pera_asiatica_91.png', 'pera_asiatica_92.png', 'pera_asiatica_93.png', 'pera_asiatica_94.png', 'pera_asiatica_95.png', 'pera_asiatica_96.png', 'pera_asiatica_97.png', 'pera_asiatica_98.png', 'pera_asiatica_99.png', 'pina_miel_1.png', 'pina_miel_10.png', 'pina_miel_100.png', 'pina_miel_101.png', 'pina_miel_102.png', 'pina_miel_103.png', 'pina_miel_104.png', 'pina_miel_105.png', 'pina_miel_106.png', 'pina_miel_107.png', 'pina_miel_108.png', 'pina_miel_109.png', 'pina_miel_11.png', 'pina_miel_110.png', 'pina_miel_111.png', 'pina_miel_112.png', 'pina_miel_113.png', 'pina_miel_114.png', 'pina_miel_115.png', 'pina_miel_116.png', 'pina_miel_117.png', 'pina_miel_118.png', 'pina_miel_119.png', 'pina_miel_12.png', 'pina_miel_120.png', 'pina_miel_121.png', 'pina_miel_122.png', 'pina_miel_123.png', 'pina_miel_124.png', 'pina_miel_125.png', 'pina_miel_126.png', 'pina_miel_127.png', 'pina_miel_128.png', 'pina_miel_129.png', 'pina_miel_13.png', 'pina_miel_130.png', 'pina_miel_131.png', 'pina_miel_132.png', 'pina_miel_133.png', 'pina_miel_134.png', 'pina_miel_135.png', 'pina_miel_136.png', 'pina_miel_137.png', 'pina_miel_138.png', 'pina_miel_139.png', 'pina_miel_14.png', 'pina_miel_140.png', 'pina_miel_141.png', 'pina_miel_142.png', 'pina_miel_143.png', 'pina_miel_144.png', 'pina_miel_145.png', 'pina_miel_146.png', 'pina_miel_147.png', 'pina_miel_148.png', 'pina_miel_149.png', 'pina_miel_15.png', 'pina_miel_150.png', 'pina_miel_151.png', 'pina_miel_152.png', 'pina_miel_153.png', 'pina_miel_154.png', 'pina_miel_155.png', 'pina_miel_156.png', 'pina_miel_157.png', 'pina_miel_158.png', 'pina_miel_159.png', 'pina_miel_16.png', 'pina_miel_160.png', 'pina_miel_161.png', 'pina_miel_162.png', 'pina_miel_163.png', 'pina_miel_164.png', 'pina_miel_165.png', 'pina_miel_166.png', 'pina_miel_167.png', 'pina_miel_168.png', 'pina_miel_169.png', 'pina_miel_17.png', 'pina_miel_170.png', 'pina_miel_171.png', 'pina_miel_172.png', 'pina_miel_173.png', 'pina_miel_174.png', 'pina_miel_175.png', 'pina_miel_176.png', 'pina_miel_177.png', 'pina_miel_178.png', 'pina_miel_179.png', 'pina_miel_18.png', 'pina_miel_180.png', 'pina_miel_181.png', 'pina_miel_182.png', 'pina_miel_183.png', 'pina_miel_184.png', 'pina_miel_185.png', 'pina_miel_186.png', 'pina_miel_187.png', 'pina_miel_188.png', 'pina_miel_189.png', 'pina_miel_19.png', 'pina_miel_190.png', 'pina_miel_191.png', 'pina_miel_192.png', 'pina_miel_193.png', 'pina_miel_194.png', 'pina_miel_195.png', 'pina_miel_196.png', 'pina_miel_197.png', 'pina_miel_198.png', 'pina_miel_199.png', 'pina_miel_2.png', 'pina_miel_20.png', 'pina_miel_200.png', 'pina_miel_201.png', 'pina_miel_202.png', 'pina_miel_203.png', 'pina_miel_204.png', 'pina_miel_205.png', 'pina_miel_206.png', 'pina_miel_207.png', 'pina_miel_208.png', 'pina_miel_209.png', 'pina_miel_21.png', 'pina_miel_210.png', 'pina_miel_211.png', 'pina_miel_212.png', 'pina_miel_213.png', 'pina_miel_214.png', 'pina_miel_215.png', 'pina_miel_216.png', 'pina_miel_217.png', 'pina_miel_218.png', 'pina_miel_219.png', 'pina_miel_22.png', 'pina_miel_220.png', 'pina_miel_221.png', 'pina_miel_222.png', 'pina_miel_223.png', 'pina_miel_224.png', 'pina_miel_225.png', 'pina_miel_226.png', 'pina_miel_227.png', 'pina_miel_228.png', 'pina_miel_229.png', 'pina_miel_23.png', 'pina_miel_230.png', 'pina_miel_231.png', 'pina_miel_232.png', 'pina_miel_233.png', 'pina_miel_234.png', 'pina_miel_235.png', 'pina_miel_236.png', 'pina_miel_237.png', 'pina_miel_238.png', 'pina_miel_239.png', 'pina_miel_24.png', 'pina_miel_240.png', 'pina_miel_241.png', 'pina_miel_242.png', 'pina_miel_25.png', 'pina_miel_26.png', 'pina_miel_27.png', 'pina_miel_28.png', 'pina_miel_29.png', 'pina_miel_3.png', 'pina_miel_30.png', 'pina_miel_31.png', 'pina_miel_32.png', 'pina_miel_33.png', 'pina_miel_34.png', 'pina_miel_35.png', 'pina_miel_36.png', 'pina_miel_37.png', 'pina_miel_38.png', 'pina_miel_39.png', 'pina_miel_4.png', 'pina_miel_40.png', 'pina_miel_41.png', 'pina_miel_42.png', 'pina_miel_43.png', 'pina_miel_44.png', 'pina_miel_45.png', 'pina_miel_46.png', 'pina_miel_47.png', 'pina_miel_48.png', 'pina_miel_49.png', 'pina_miel_5.png', 'pina_miel_50.png', 'pina_miel_51.png', 'pina_miel_52.png', 'pina_miel_53.png', 'pina_miel_54.png', 'pina_miel_55.png', 'pina_miel_56.png', 'pina_miel_57.png', 'pina_miel_58.png', 'pina_miel_59.png', 'pina_miel_6.png', 'pina_miel_60.png', 'pina_miel_61.png', 'pina_miel_62.png', 'pina_miel_63.png', 'pina_miel_64.png', 'pina_miel_65.png', 'pina_miel_66.png', 'pina_miel_67.png', 'pina_miel_68.png', 'pina_miel_69.png', 'pina_miel_7.png', 'pina_miel_70.png', 'pina_miel_71.png', 'pina_miel_72.png', 'pina_miel_73.png', 'pina_miel_74.png', 'pina_miel_75.png', 'pina_miel_76.png', 'pina_miel_77.png', 'pina_miel_78.png', 'pina_miel_79.png', 'pina_miel_8.png', 'pina_miel_80.png', 'pina_miel_81.png', 'pina_miel_82.png', 'pina_miel_83.png', 'pina_miel_84.png', 'pina_miel_85.png', 'pina_miel_86.png', 'pina_miel_87.png', 'pina_miel_88.png', 'pina_miel_89.png', 'pina_miel_9.png', 'pina_miel_90.png', 'pina_miel_91.png', 'pina_miel_92.png', 'pina_miel_93.png', 'pina_miel_94.png', 'pina_miel_95.png', 'pina_miel_96.png', 'pina_miel_97.png', 'pina_miel_98.png', 'pina_miel_99.png', 'saltillo_1.png', 'saltillo_10.png', 'saltillo_100.png', 'saltillo_101.png', 'saltillo_102.png', 'saltillo_103.png', 'saltillo_104.png', 'saltillo_105.png', 'saltillo_106.png', 'saltillo_107.png', 'saltillo_108.png', 'saltillo_109.png', 'saltillo_11.png', 'saltillo_110.png', 'saltillo_111.png', 'saltillo_112.png', 'saltillo_113.png', 'saltillo_114.png', 'saltillo_115.png', 'saltillo_116.png', 'saltillo_117.png', 'saltillo_118.png', 'saltillo_119.png', 'saltillo_12.png', 'saltillo_120.png', 'saltillo_121.png', 'saltillo_122.png', 'saltillo_123.png', 'saltillo_124.png', 'saltillo_125.png', 'saltillo_126.png', 'saltillo_127.png', 'saltillo_128.png', 'saltillo_129.png', 'saltillo_13.png', 'saltillo_130.png', 'saltillo_131.png', 'saltillo_132.png', 'saltillo_133.png', 'saltillo_134.png', 'saltillo_135.png', 'saltillo_136.png', 'saltillo_137.png', 'saltillo_138.png', 'saltillo_139.png', 'saltillo_14.png', 'saltillo_140.png', 'saltillo_141.png', 'saltillo_142.png', 'saltillo_143.png', 'saltillo_144.png', 'saltillo_145.png', 'saltillo_146.png', 'saltillo_147.png', 'saltillo_148.png', 'saltillo_149.png', 'saltillo_15.png', 'saltillo_150.png', 'saltillo_151.png', 'saltillo_152.png', 'saltillo_153.png', 'saltillo_154.png', 'saltillo_155.png', 'saltillo_156.png', 'saltillo_157.png', 'saltillo_158.png', 'saltillo_159.png', 'saltillo_16.png', 'saltillo_160.png', 'saltillo_161.png', 'saltillo_162.png', 'saltillo_163.png', 'saltillo_164.png', 'saltillo_165.png', 'saltillo_166.png', 'saltillo_167.png', 'saltillo_168.png', 'saltillo_169.png', 'saltillo_17.png', 'saltillo_170.png', 'saltillo_171.png', 'saltillo_172.png', 'saltillo_173.png', 'saltillo_174.png', 'saltillo_175.png', 'saltillo_176.png', 'saltillo_177.png', 'saltillo_178.png', 'saltillo_179.png', 'saltillo_18.png', 'saltillo_180.png', 'saltillo_181.png', 'saltillo_182.png', 'saltillo_183.png', 'saltillo_184.png', 'saltillo_185.png', 'saltillo_186.png', 'saltillo_187.png', 'saltillo_188.png', 'saltillo_189.png', 'saltillo_19.png', 'saltillo_190.png', 'saltillo_191.png', 'saltillo_192.png', 'saltillo_193.png', 'saltillo_194.png', 'saltillo_195.png', 'saltillo_196.png', 'saltillo_197.png', 'saltillo_198.png', 'saltillo_199.png', 'saltillo_2.png', 'saltillo_20.png', 'saltillo_200.png', 'saltillo_201.png', 'saltillo_202.png', 'saltillo_203.png', 'saltillo_204.png', 'saltillo_205.png', 'saltillo_206.png', 'saltillo_207.png', 'saltillo_208.png', 'saltillo_209.png', 'saltillo_21.png', 'saltillo_210.png', 'saltillo_211.png', 'saltillo_212.png', 'saltillo_213.png', 'saltillo_214.png', 'saltillo_215.png', 'saltillo_216.png', 'saltillo_217.png', 'saltillo_218.png', 'saltillo_219.png', 'saltillo_22.png', 'saltillo_220.png', 'saltillo_221.png', 'saltillo_222.png', 'saltillo_223.png', 'saltillo_224.png', 'saltillo_225.png', 'saltillo_226.png', 'saltillo_227.png', 'saltillo_228.png', 'saltillo_229.png', 'saltillo_23.png', 'saltillo_230.png', 'saltillo_231.png', 'saltillo_232.png', 'saltillo_233.png', 'saltillo_234.png', 'saltillo_235.png', 'saltillo_236.png', 'saltillo_237.png', 'saltillo_238.png', 'saltillo_239.png', 'saltillo_24.png', 'saltillo_240.png', 'saltillo_241.png', 'saltillo_242.png', 'saltillo_243.png', 'saltillo_244.png', 'saltillo_245.png', 'saltillo_246.png', 'saltillo_247.png', 'saltillo_248.png', 'saltillo_249.png', 'saltillo_25.png', 'saltillo_250.png', 'saltillo_251.png', 'saltillo_252.png', 'saltillo_253.png', 'saltillo_254.png', 'saltillo_255.png', 'saltillo_256.png', 'saltillo_257.png', 'saltillo_258.png', 'saltillo_259.png', 'saltillo_26.png', 'saltillo_260.png', 'saltillo_261.png', 'saltillo_262.png', 'saltillo_263.png', 'saltillo_264.png', 'saltillo_265.png', 'saltillo_266.png', 'saltillo_267.png', 'saltillo_268.png', 'saltillo_269.png', 'saltillo_27.png', 'saltillo_270.png', 'saltillo_271.png', 'saltillo_272.png', 'saltillo_273.png', 'saltillo_274.png', 'saltillo_275.png', 'saltillo_276.png', 'saltillo_277.png', 'saltillo_278.png', 'saltillo_279.png', 'saltillo_28.png', 'saltillo_280.png', 'saltillo_281.png', 'saltillo_282.png', 'saltillo_283.png', 'saltillo_284.png', 'saltillo_285.png', 'saltillo_286.png', 'saltillo_287.png', 'saltillo_288.png', 'saltillo_289.png', 'saltillo_29.png', 'saltillo_290.png', 'saltillo_291.png', 'saltillo_292.png', 'saltillo_293.png', 'saltillo_294.png', 'saltillo_295.png', 'saltillo_296.png', 'saltillo_297.png', 'saltillo_298.png', 'saltillo_299.png', 'saltillo_3.png', 'saltillo_30.png', 'saltillo_300.png', 'saltillo_301.png', 'saltillo_302.png', 'saltillo_303.png', 'saltillo_304.png', 'saltillo_305.png', 'saltillo_306.png', 'saltillo_307.png', 'saltillo_308.png', 'saltillo_309.png', 'saltillo_31.png', 'saltillo_310.png', 'saltillo_311.png', 'saltillo_312.png', 'saltillo_313.png', 'saltillo_314.png', 'saltillo_315.png', 'saltillo_316.png', 'saltillo_317.png', 'saltillo_318.png', 'saltillo_319.png', 'saltillo_32.png', 'saltillo_320.png', 'saltillo_321.png', 'saltillo_322.png', 'saltillo_323.png', 'saltillo_324.png', 'saltillo_325.png', 'saltillo_326.png', 'saltillo_327.png', 'saltillo_328.png', 'saltillo_329.png', 'saltillo_33.png', 'saltillo_330.png', 'saltillo_331.png', 'saltillo_332.png', 'saltillo_333.png', 'saltillo_334.png', 'saltillo_335.png', 'saltillo_336.png', 'saltillo_337.png', 'saltillo_338.png', 'saltillo_339.png', 'saltillo_34.png', 'saltillo_340.png', 'saltillo_341.png', 'saltillo_342.png', 'saltillo_343.png', 'saltillo_344.png', 'saltillo_345.png', 'saltillo_346.png', 'saltillo_347.png', 'saltillo_348.png', 'saltillo_349.png', 'saltillo_35.png', 'saltillo_350.png', 'saltillo_351.png', 'saltillo_352.png', 'saltillo_353.png', 'saltillo_354.png', 'saltillo_355.png', 'saltillo_356.png', 'saltillo_357.png', 'saltillo_358.png', 'saltillo_359.png', 'saltillo_36.png', 'saltillo_360.png', 'saltillo_361.png', 'saltillo_37.png', 'saltillo_38.png', 'saltillo_39.png', 'saltillo_4.png', 'saltillo_40.png', 'saltillo_41.png', 'saltillo_42.png', 'saltillo_43.png', 'saltillo_44.png', 'saltillo_45.png', 'saltillo_46.png', 'saltillo_47.png', 'saltillo_48.png', 'saltillo_49.png', 'saltillo_5.png', 'saltillo_50.png', 'saltillo_51.png', 'saltillo_52.png', 'saltillo_53.png', 'saltillo_54.png', 'saltillo_55.png', 'saltillo_56.png', 'saltillo_57.png', 'saltillo_58.png', 'saltillo_59.png', 'saltillo_6.png', 'saltillo_60.png', 'saltillo_61.png', 'saltillo_62.png', 'saltillo_63.png', 'saltillo_64.png', 'saltillo_65.png', 'saltillo_66.png', 'saltillo_67.png', 'saltillo_68.png', 'saltillo_69.png', 'saltillo_7.png', 'saltillo_70.png', 'saltillo_71.png', 'saltillo_72.png', 'saltillo_73.png', 'saltillo_74.png', 'saltillo_75.png', 'saltillo_76.png', 'saltillo_77.png', 'saltillo_78.png', 'saltillo_79.png', 'saltillo_8.png', 'saltillo_80.png', 'saltillo_81.png', 'saltillo_82.png', 'saltillo_83.png', 'saltillo_84.png', 'saltillo_85.png', 'saltillo_86.png', 'saltillo_87.png', 'saltillo_88.png', 'saltillo_89.png', 'saltillo_9.png', 'saltillo_90.png', 'saltillo_91.png', 'saltillo_92.png', 'saltillo_93.png', 'saltillo_94.png', 'saltillo_95.png', 'saltillo_96.png', 'saltillo_97.png', 'saltillo_98.png', 'saltillo_99.png', 'tomatillo_1.png', 'tomatillo_10.png', 'tomatillo_11.png', 'tomatillo_12.png', 'tomatillo_13.png', 'tomatillo_14.png', 'tomatillo_15.png', 'tomatillo_16.png', 'tomatillo_17.png', 'tomatillo_18.png', 'tomatillo_19.png', 'tomatillo_2.png', 'tomatillo_20.png', 'tomatillo_21.png', 'tomatillo_22.png', 'tomatillo_23.png', 'tomatillo_24.png', 'tomatillo_25.png', 'tomatillo_26.png', 'tomatillo_27.png', 'tomatillo_28.png', 'tomatillo_29.png', 'tomatillo_3.png', 'tomatillo_30.png', 'tomatillo_31.png', 'tomatillo_32.png', 'tomatillo_33.png', 'tomatillo_34.png', 'tomatillo_35.png', 'tomatillo_36.png', 'tomatillo_37.png', 'tomatillo_38.png', 'tomatillo_39.png', 'tomatillo_4.png', 'tomatillo_40.png', 'tomatillo_41.png', 'tomatillo_42.png', 'tomatillo_43.png', 'tomatillo_44.png', 'tomatillo_45.png', 'tomatillo_46.png', 'tomatillo_47.png', 'tomatillo_48.png', 'tomatillo_49.png', 'tomatillo_5.png', 'tomatillo_50.png', 'tomatillo_51.png', 'tomatillo_52.png', 'tomatillo_53.png', 'tomatillo_54.png', 'tomatillo_55.png', 'tomatillo_56.png', 'tomatillo_57.png', 'tomatillo_58.png', 'tomatillo_59.png', 'tomatillo_6.png', 'tomatillo_60.png', 'tomatillo_61.png', 'tomatillo_62.png', 'tomatillo_63.png', 'tomatillo_64.png', 'tomatillo_65.png', 'tomatillo_66.png', 'tomatillo_67.png', 'tomatillo_68.png', 'tomatillo_69.png', 'tomatillo_7.png', 'tomatillo_70.png', 'tomatillo_71.png', 'tomatillo_72.png', 'tomatillo_73.png', 'tomatillo_74.png', 'tomatillo_75.png', 'tomatillo_76.png', 'tomatillo_77.png', 'tomatillo_78.png', 'tomatillo_79.png', 'tomatillo_8.png', 'tomatillo_80.png', 'tomatillo_81.png', 'tomatillo_82.png', 'tomatillo_83.png', 'tomatillo_84.png', 'tomatillo_85.png', 'tomatillo_86.png', 'tomatillo_87.png', 'tomatillo_88.png', 'tomatillo_9.png', 'acelga_1.png', 'acelga_10.png', 'acelga_100.png', 'acelga_101.png', 'acelga_102.png', 'acelga_103.png', 'acelga_104.png', 'acelga_105.png', 'acelga_106.png', 'acelga_107.png', 'acelga_108.png', 'acelga_109.png', 'acelga_11.png', 'acelga_110.png', 'acelga_111.png', 'acelga_112.png', 'acelga_113.png', 'acelga_114.png', 'acelga_115.png', 'acelga_116.png', 'acelga_117.png', 'acelga_118.png', 'acelga_119.png', 'acelga_12.png', 'acelga_120.png', 'acelga_121.png', 'acelga_122.png', 'acelga_123.png', 'acelga_124.png', 'acelga_125.png', 'acelga_126.png', 'acelga_127.png', 'acelga_128.png', 'acelga_129.png', 'acelga_13.png', 'acelga_130.png', 'acelga_131.png', 'acelga_132.png', 'acelga_133.png', 'acelga_134.png', 'acelga_135.png', 'acelga_136.png', 'acelga_137.png', 'acelga_138.png', 'acelga_139.png', 'acelga_14.png', 'acelga_140.png', 'acelga_141.png', 'acelga_142.png', 'acelga_143.png', 'acelga_144.png', 'acelga_145.png', 'acelga_146.png', 'acelga_147.png', 'acelga_148.png', 'acelga_149.png', 'acelga_15.png', 'acelga_150.png', 'acelga_151.png', 'acelga_152.png', 'acelga_153.png', 'acelga_154.png', 'acelga_155.png', 'acelga_156.png', 'acelga_157.png', 'acelga_158.png', 'acelga_159.png', 'acelga_16.png', 'acelga_160.png', 'acelga_161.png', 'acelga_162.png', 'acelga_163.png', 'acelga_164.png', 'acelga_165.png', 'acelga_166.png', 'acelga_167.png', 'acelga_168.png', 'acelga_169.png', 'acelga_17.png', 'acelga_170.png', 'acelga_171.png', 'acelga_172.png', 'acelga_173.png', 'acelga_174.png', 'acelga_175.png', 'acelga_176.png', 'acelga_177.png', 'acelga_178.png', 'acelga_179.png', 'acelga_18.png', 'acelga_180.png', 'acelga_181.png', 'acelga_182.png', 'acelga_183.png', 'acelga_184.png', 'acelga_185.png', 'acelga_186.png', 'acelga_187.png', 'acelga_188.png', 'acelga_189.png', 'acelga_19.png', 'acelga_190.png', 'acelga_191.png', 'acelga_192.png', 'acelga_193.png', 'acelga_194.png', 'acelga_195.png', 'acelga_196.png', 'acelga_197.png', 'acelga_198.png', 'acelga_199.png', 'acelga_2.png', 'acelga_20.png', 'acelga_200.png', 'acelga_201.png', 'acelga_202.png', 'acelga_203.png', 'acelga_204.png', 'acelga_205.png', 'acelga_206.png', 'acelga_207.png', 'acelga_208.png', 'acelga_209.png', 'acelga_21.png', 'acelga_210.png', 'acelga_211.png', 'acelga_212.png', 'acelga_213.png', 'acelga_214.png', 'acelga_215.png', 'acelga_216.png', 'acelga_217.png', 'acelga_218.png', 'acelga_219.png', 'acelga_22.png', 'acelga_220.png', 'acelga_221.png', 'acelga_222.png', 'acelga_223.png', 'acelga_224.png', 'acelga_225.png', 'acelga_226.png', 'acelga_227.png', 'acelga_228.png', 'acelga_229.png', 'acelga_23.png', 'acelga_230.png', 'acelga_231.png', 'acelga_232.png', 'acelga_233.png', 'acelga_234.png', 'acelga_235.png', 'acelga_236.png', 'acelga_237.png', 'acelga_238.png', 'acelga_239.png', 'acelga_24.png', 'acelga_240.png', 'acelga_241.png', 'acelga_242.png', 'acelga_243.png', 'acelga_244.png', 'acelga_245.png', 'acelga_246.png', 'acelga_247.png', 'acelga_248.png', 'acelga_249.png', 'acelga_25.png', 'acelga_250.png', 'acelga_251.png', 'acelga_252.png', 'acelga_253.png', 'acelga_254.png', 'acelga_255.png', 'acelga_256.png', 'acelga_257.png', 'acelga_258.png', 'acelga_259.png', 'acelga_26.png', 'acelga_260.png', 'acelga_261.png', 'acelga_262.png', 'acelga_263.png', 'acelga_264.png', 'acelga_265.png', 'acelga_266.png', 'acelga_267.png', 'acelga_268.png', 'acelga_269.png', 'acelga_27.png', 'acelga_270.png', 'acelga_271.png', 'acelga_272.png', 'acelga_273.png', 'acelga_274.png', 'acelga_275.png', 'acelga_276.png', 'acelga_277.png', 'acelga_278.png', 'acelga_279.png', 'acelga_28.png', 'acelga_280.png', 'acelga_281.png', 'acelga_282.png', 'acelga_283.png', 'acelga_284.png', 'acelga_285.png', 'acelga_286.png', 'acelga_287.png', 'acelga_288.png', 'acelga_289.png', 'acelga_29.png', 'acelga_290.png', 'acelga_291.png', 'acelga_292.png', 'acelga_293.png', 'acelga_294.png', 'acelga_295.png', 'acelga_296.png', 'acelga_297.png', 'acelga_298.png', 'acelga_299.png', 'acelga_3.png', 'acelga_30.png', 'acelga_300.png', 'acelga_301.png', 'acelga_302.png', 'acelga_303.png', 'acelga_304.png', 'acelga_305.png', 'acelga_306.png', 'acelga_307.png', 'acelga_308.png', 'acelga_309.png', 'acelga_31.png', 'acelga_310.png', 'acelga_311.png', 'acelga_312.png', 'acelga_313.png', 'acelga_314.png', 'acelga_315.png', 'acelga_316.png', 'acelga_317.png', 'acelga_318.png', 'acelga_319.png', 'acelga_32.png', 'acelga_320.png', 'acelga_321.png', 'acelga_322.png', 'acelga_323.png', 'acelga_324.png', 'acelga_325.png', 'acelga_326.png', 'acelga_327.png', 'acelga_328.png', 'acelga_329.png', 'acelga_33.png', 'acelga_330.png', 'acelga_331.png', 'acelga_332.png', 'acelga_333.png', 'acelga_334.png', 'acelga_335.png', 'acelga_336.png', 'acelga_337.png', 'acelga_338.png', 'acelga_339.png', 'acelga_34.png', 'acelga_340.png', 'acelga_341.png', 'acelga_342.png', 'acelga_343.png', 'acelga_344.png', 'acelga_345.png', 'acelga_346.png', 'acelga_347.png', 'acelga_348.png', 'acelga_349.png', 'acelga_35.png', 'acelga_350.png', 'acelga_351.png', 'acelga_352.png', 'acelga_353.png', 'acelga_354.png', 'acelga_355.png', 'acelga_356.png', 'acelga_357.png', 'acelga_358.png', 'acelga_359.png', 'acelga_36.png', 'acelga_360.png', 'acelga_361.png', 'acelga_362.png', 'acelga_363.png', 'acelga_364.png', 'acelga_365.png', 'acelga_366.png', 'acelga_367.png', 'acelga_368.png', 'acelga_369.png', 'acelga_37.png', 'acelga_370.png', 'acelga_371.png', 'acelga_372.png', 'acelga_373.png', 'acelga_374.png', 'acelga_375.png', 'acelga_376.png', 'acelga_377.png', 'acelga_378.png', 'acelga_379.png', 'acelga_38.png', 'acelga_380.png', 'acelga_381.png', 'acelga_382.png', 'acelga_383.png', 'acelga_384.png', 'acelga_385.png', 'acelga_386.png', 'acelga_387.png', 'acelga_388.png', 'acelga_389.png', 'acelga_39.png', 'acelga_390.png', 'acelga_391.png', 'acelga_392.png', 'acelga_393.png', 'acelga_394.png', 'acelga_395.png', 'acelga_396.png', 'acelga_397.png', 'acelga_398.png', 'acelga_399.png', 'acelga_4.png', 'acelga_40.png', 'acelga_400.png', 'acelga_401.png', 'acelga_402.png', 'acelga_403.png', 'acelga_404.png', 'acelga_405.png', 'acelga_406.png', 'acelga_407.png', 'acelga_408.png', 'acelga_409.png', 'acelga_41.png', 'acelga_410.png', 'acelga_411.png', 'acelga_412.png', 'acelga_413.png', 'acelga_414.png', 'acelga_415.png', 'acelga_416.png', 'acelga_417.png', 'acelga_418.png', 'acelga_419.png', 'acelga_42.png', 'acelga_420.png', 'acelga_421.png', 'acelga_422.png', 'acelga_423.png', 'acelga_424.png', 'acelga_425.png', 'acelga_426.png', 'acelga_427.png', 'acelga_428.png', 'acelga_429.png', 'acelga_43.png', 'acelga_430.png', 'acelga_431.png', 'acelga_432.png', 'acelga_433.png', 'acelga_434.png', 'acelga_435.png', 'acelga_436.png', 'acelga_437.png', 'acelga_438.png', 'acelga_439.png', 'acelga_44.png', 'acelga_440.png', 'acelga_441.png', 'acelga_442.png', 'acelga_443.png', 'acelga_444.png', 'acelga_445.png', 'acelga_446.png', 'acelga_447.png', 'acelga_448.png', 'acelga_449.png', 'acelga_45.png', 'acelga_450.png', 'acelga_451.png', 'acelga_452.png', 'acelga_453.png', 'acelga_454.png', 'acelga_455.png', 'acelga_456.png', 'acelga_457.png', 'acelga_458.png', 'acelga_459.png', 'acelga_46.png', 'acelga_460.png', 'acelga_461.png', 'acelga_462.png', 'acelga_463.png', 'acelga_464.png', 'acelga_47.png', 'acelga_48.png', 'acelga_49.png', 'acelga_5.png', 'acelga_50.png', 'acelga_51.png', 'acelga_52.png', 'acelga_53.png', 'acelga_54.png', 'acelga_55.png', 'acelga_56.png', 'acelga_57.png', 'acelga_58.png', 'acelga_59.png', 'acelga_6.png', 'acelga_60.png', 'acelga_61.png', 'acelga_62.png', 'acelga_63.png', 'acelga_64.png', 'acelga_65.png', 'acelga_66.png', 'acelga_67.png', 'acelga_68.png', 'acelga_69.png', 'acelga_7.png', 'acelga_70.png', 'acelga_71.png', 'acelga_72.png', 'acelga_73.png', 'acelga_74.png', 'acelga_75.png', 'acelga_76.png', 'acelga_77.png', 'acelga_78.png', 'acelga_79.png', 'acelga_8.png', 'acelga_80.png', 'acelga_81.png', 'acelga_82.png', 'acelga_83.png', 'acelga_84.png', 'acelga_85.png', 'acelga_86.png', 'acelga_87.png', 'acelga_88.png', 'acelga_89.png', 'acelga_9.png', 'acelga_90.png', 'acelga_91.png', 'acelga_92.png', 'acelga_93.png', 'acelga_94.png', 'acelga_95.png', 'acelga_96.png', 'acelga_97.png', 'acelga_98.png', 'acelga_99.png', 'espinaca_1.png', 'espinaca_10.png', 'espinaca_100.png', 'espinaca_101.png', 'espinaca_102.png', 'espinaca_103.png', 'espinaca_104.png', 'espinaca_105.png', 'espinaca_106.png', 'espinaca_107.png', 'espinaca_108.png', 'espinaca_109.png', 'espinaca_11.png', 'espinaca_110.png', 'espinaca_111.png', 'espinaca_112.png', 'espinaca_113.png', 'espinaca_114.png', 'espinaca_115.png', 'espinaca_116.png', 'espinaca_117.png', 'espinaca_118.png', 'espinaca_119.png', 'espinaca_12.png', 'espinaca_120.png', 'espinaca_121.png', 'espinaca_122.png', 'espinaca_123.png', 'espinaca_124.png', 'espinaca_125.png', 'espinaca_126.png', 'espinaca_127.png', 'espinaca_128.png', 'espinaca_129.png', 'espinaca_13.png', 'espinaca_130.png', 'espinaca_131.png', 'espinaca_132.png', 'espinaca_133.png', 'espinaca_134.png', 'espinaca_135.png', 'espinaca_136.png', 'espinaca_137.png', 'espinaca_138.png', 'espinaca_139.png', 'espinaca_14.png', 'espinaca_140.png', 'espinaca_141.png', 'espinaca_142.png', 'espinaca_143.png', 'espinaca_144.png', 'espinaca_145.png', 'espinaca_146.png', 'espinaca_147.png', 'espinaca_148.png', 'espinaca_149.png', 'espinaca_15.png', 'espinaca_150.png', 'espinaca_151.png', 'espinaca_152.png', 'espinaca_153.png', 'espinaca_154.png', 'espinaca_155.png', 'espinaca_156.png', 'espinaca_157.png', 'espinaca_158.png', 'espinaca_159.png', 'espinaca_16.png', 'espinaca_160.png', 'espinaca_161.png', 'espinaca_162.png', 'espinaca_163.png', 'espinaca_164.png', 'espinaca_165.png', 'espinaca_166.png', 'espinaca_167.png', 'espinaca_168.png', 'espinaca_169.png', 'espinaca_17.png', 'espinaca_170.png', 'espinaca_171.png', 'espinaca_172.png', 'espinaca_173.png', 'espinaca_174.png', 'espinaca_175.png', 'espinaca_176.png', 'espinaca_177.png', 'espinaca_178.png', 'espinaca_179.png', 'espinaca_18.png', 'espinaca_180.png', 'espinaca_181.png', 'espinaca_182.png', 'espinaca_183.png', 'espinaca_184.png', 'espinaca_185.png', 'espinaca_186.png', 'espinaca_187.png', 'espinaca_188.png', 'espinaca_189.png', 'espinaca_19.png', 'espinaca_190.png', 'espinaca_191.png', 'espinaca_192.png', 'espinaca_193.png', 'espinaca_194.png', 'espinaca_195.png', 'espinaca_196.png', 'espinaca_197.png', 'espinaca_198.png', 'espinaca_199.png', 'espinaca_2.png', 'espinaca_20.png', 'espinaca_200.png', 'espinaca_201.png', 'espinaca_202.png', 'espinaca_203.png', 'espinaca_204.png', 'espinaca_205.png', 'espinaca_206.png', 'espinaca_207.png', 'espinaca_208.png', 'espinaca_209.png', 'espinaca_21.png', 'espinaca_210.png', 'espinaca_211.png', 'espinaca_212.png', 'espinaca_213.png', 'espinaca_214.png', 'espinaca_215.png', 'espinaca_216.png', 'espinaca_217.png', 'espinaca_218.png', 'espinaca_219.png', 'espinaca_22.png', 'espinaca_220.png', 'espinaca_221.png', 'espinaca_222.png', 'espinaca_223.png', 'espinaca_224.png', 'espinaca_225.png', 'espinaca_226.png', 'espinaca_227.png', 'espinaca_228.png', 'espinaca_229.png', 'espinaca_23.png', 'espinaca_230.png', 'espinaca_231.png', 'espinaca_232.png', 'espinaca_233.png', 'espinaca_234.png', 'espinaca_235.png', 'espinaca_236.png', 'espinaca_237.png', 'espinaca_238.png', 'espinaca_239.png', 'espinaca_24.png', 'espinaca_240.png', 'espinaca_241.png', 'espinaca_242.png', 'espinaca_243.png', 'espinaca_244.png', 'espinaca_245.png', 'espinaca_246.png', 'espinaca_247.png', 'espinaca_248.png', 'espinaca_249.png', 'espinaca_25.png', 'espinaca_250.png', 'espinaca_251.png', 'espinaca_252.png', 'espinaca_253.png', 'espinaca_254.png', 'espinaca_255.png', 'espinaca_256.png', 'espinaca_257.png', 'espinaca_258.png', 'espinaca_259.png', 'espinaca_26.png', 'espinaca_260.png', 'espinaca_261.png', 'espinaca_262.png', 'espinaca_263.png', 'espinaca_264.png', 'espinaca_265.png', 'espinaca_266.png', 'espinaca_267.png', 'espinaca_268.png', 'espinaca_269.png', 'espinaca_27.png', 'espinaca_270.png', 'espinaca_271.png', 'espinaca_272.png', 'espinaca_273.png', 'espinaca_274.png', 'espinaca_275.png', 'espinaca_276.png', 'espinaca_277.png', 'espinaca_278.png', 'espinaca_279.png', 'espinaca_28.png', 'espinaca_280.png', 'espinaca_281.png', 'espinaca_282.png', 'espinaca_283.png', 'espinaca_284.png', 'espinaca_285.png', 'espinaca_286.png', 'espinaca_287.png', 'espinaca_288.png', 'espinaca_289.png', 'espinaca_29.png', 'espinaca_290.png', 'espinaca_291.png', 'espinaca_292.png', 'espinaca_293.png', 'espinaca_294.png', 'espinaca_295.png', 'espinaca_296.png', 'espinaca_297.png', 'espinaca_298.png', 'espinaca_299.png', 'espinaca_3.png', 'espinaca_30.png', 'espinaca_300.png', 'espinaca_301.png', 'espinaca_302.png', 'espinaca_303.png', 'espinaca_304.png', 'espinaca_305.png', 'espinaca_306.png', 'espinaca_307.png', 'espinaca_308.png', 'espinaca_309.png', 'espinaca_31.png', 'espinaca_310.png', 'espinaca_311.png', 'espinaca_312.png', 'espinaca_313.png', 'espinaca_314.png', 'espinaca_315.png', 'espinaca_316.png', 'espinaca_317.png', 'espinaca_318.png', 'espinaca_319.png', 'espinaca_32.png', 'espinaca_320.png', 'espinaca_321.png', 'espinaca_33.png', 'espinaca_34.png', 'espinaca_35.png', 'espinaca_36.png', 'espinaca_37.png', 'espinaca_38.png', 'espinaca_39.png', 'espinaca_4.png', 'espinaca_40.png', 'espinaca_41.png', 'espinaca_42.png', 'espinaca_43.png', 'espinaca_44.png', 'espinaca_45.png', 'espinaca_46.png', 'espinaca_47.png', 'espinaca_48.png', 'espinaca_49.png', 'espinaca_5.png', 'espinaca_50.png', 'espinaca_51.png', 'espinaca_52.png', 'espinaca_53.png', 'espinaca_54.png', 'espinaca_55.png', 'espinaca_56.png', 'espinaca_57.png', 'espinaca_58.png', 'espinaca_59.png', 'espinaca_6.png', 'espinaca_60.png', 'espinaca_61.png', 'espinaca_62.png', 'espinaca_63.png', 'espinaca_64.png', 'espinaca_65.png', 'espinaca_66.png', 'espinaca_67.png', 'espinaca_68.png', 'espinaca_69.png', 'espinaca_7.png', 'espinaca_70.png', 'espinaca_71.png', 'espinaca_72.png', 'espinaca_73.png', 'espinaca_74.png', 'espinaca_75.png', 'espinaca_76.png', 'espinaca_77.png', 'espinaca_78.png', 'espinaca_79.png', 'espinaca_8.png', 'espinaca_80.png', 'espinaca_81.png', 'espinaca_82.png', 'espinaca_83.png', 'espinaca_84.png', 'espinaca_85.png', 'espinaca_86.png', 'espinaca_87.png', 'espinaca_88.png', 'espinaca_89.png', 'espinaca_9.png', 'espinaca_90.png', 'espinaca_91.png', 'espinaca_92.png', 'espinaca_93.png', 'espinaca_94.png', 'espinaca_95.png', 'espinaca_96.png', 'espinaca_97.png', 'espinaca_98.png', 'espinaca_99.png', 'fresadilla2_1.png', 'fresadilla2_10.png', 'fresadilla2_100.png', 'fresadilla2_101.png', 'fresadilla2_102.png', 'fresadilla2_103.png', 'fresadilla2_104.png', 'fresadilla2_105.png', 'fresadilla2_106.png', 'fresadilla2_107.png', 'fresadilla2_108.png', 'fresadilla2_109.png', 'fresadilla2_11.png', 'fresadilla2_110.png', 'fresadilla2_111.png', 'fresadilla2_112.png', 'fresadilla2_113.png', 'fresadilla2_114.png', 'fresadilla2_115.png', 'fresadilla2_116.png', 'fresadilla2_117.png', 'fresadilla2_118.png', 'fresadilla2_119.png', 'fresadilla2_12.png', 'fresadilla2_13.png', 'fresadilla2_14.png', 'fresadilla2_15.png', 'fresadilla2_16.png', 'fresadilla2_17.png', 'fresadilla2_18.png', 'fresadilla2_19.png', 'fresadilla2_2.png', 'fresadilla2_20.png', 'fresadilla2_21.png', 'fresadilla2_22.png', 'fresadilla2_23.png', 'fresadilla2_24.png', 'fresadilla2_25.png', 'fresadilla2_26.png', 'fresadilla2_27.png', 'fresadilla2_28.png', 'fresadilla2_29.png', 'fresadilla2_3.png', 'fresadilla2_30.png', 'fresadilla2_31.png', 'fresadilla2_32.png', 'fresadilla2_33.png', 'fresadilla2_34.png', 'fresadilla2_35.png', 'fresadilla2_36.png', 'fresadilla2_37.png', 'fresadilla2_38.png', 'fresadilla2_39.png', 'fresadilla2_4.png', 'fresadilla2_40.png', 'fresadilla2_41.png', 'fresadilla2_42.png', 'fresadilla2_43.png', 'fresadilla2_44.png', 'fresadilla2_45.png', 'fresadilla2_46.png', 'fresadilla2_47.png', 'fresadilla2_48.png', 'fresadilla2_49.png', 'fresadilla2_5.png', 'fresadilla2_50.png', 'fresadilla2_51.png', 'fresadilla2_52.png', 'fresadilla2_53.png', 'fresadilla2_54.png', 'fresadilla2_55.png', 'fresadilla2_56.png', 'fresadilla2_57.png', 'fresadilla2_58.png', 'fresadilla2_59.png', 'fresadilla2_6.png', 'fresadilla2_60.png', 'fresadilla2_61.png', 'fresadilla2_62.png', 'fresadilla2_63.png', 'fresadilla2_64.png', 'fresadilla2_65.png', 'fresadilla2_66.png', 'fresadilla2_67.png', 'fresadilla2_68.png', 'fresadilla2_69.png', 'fresadilla2_7.png', 'fresadilla2_70.png', 'fresadilla2_71.png', 'fresadilla2_72.png', 'fresadilla2_73.png', 'fresadilla2_74.png', 'fresadilla2_75.png', 'fresadilla2_76.png', 'fresadilla2_77.png', 'fresadilla2_78.png', 'fresadilla2_79.png', 'fresadilla2_8.png', 'fresadilla2_80.png', 'fresadilla2_81.png', 'fresadilla2_82.png', 'fresadilla2_83.png', 'fresadilla2_84.png', 'fresadilla2_85.png', 'fresadilla2_86.png', 'fresadilla2_87.png', 'fresadilla2_88.png', 'fresadilla2_89.png', 'fresadilla2_9.png', 'fresadilla2_90.png', 'fresadilla2_91.png', 'fresadilla2_92.png', 'fresadilla2_93.png', 'fresadilla2_94.png', 'fresadilla2_95.png', 'fresadilla2_96.png', 'fresadilla2_97.png', 'fresadilla2_98.png', 'fresadilla2_99.png', 'fresadilla_1.png', 'fresadilla_10.png', 'fresadilla_11.png', 'fresadilla_12.png', 'fresadilla_13.png', 'fresadilla_14.png', 'fresadilla_15.png', 'fresadilla_16.png', 'fresadilla_17.png', 'fresadilla_18.png', 'fresadilla_19.png', 'fresadilla_2.png', 'fresadilla_20.png', 'fresadilla_21.png', 'fresadilla_22.png', 'fresadilla_23.png', 'fresadilla_24.png', 'fresadilla_25.png', 'fresadilla_26.png', 'fresadilla_27.png', 'fresadilla_28.png', 'fresadilla_29.png', 'fresadilla_3.png', 'fresadilla_30.png', 'fresadilla_31.png', 'fresadilla_32.png', 'fresadilla_33.png', 'fresadilla_34.png', 'fresadilla_35.png', 'fresadilla_36.png', 'fresadilla_37.png', 'fresadilla_38.png', 'fresadilla_39.png', 'fresadilla_4.png', 'fresadilla_40.png', 'fresadilla_41.png', 'fresadilla_42.png', 'fresadilla_43.png', 'fresadilla_44.png', 'fresadilla_45.png', 'fresadilla_46.png', 'fresadilla_47.png', 'fresadilla_48.png', 'fresadilla_49.png', 'fresadilla_5.png', 'fresadilla_50.png', 'fresadilla_51.png', 'fresadilla_52.png', 'fresadilla_53.png', 'fresadilla_54.png', 'fresadilla_55.png', 'fresadilla_56.png', 'fresadilla_57.png', 'fresadilla_58.png', 'fresadilla_59.png', 'fresadilla_6.png', 'fresadilla_60.png', 'fresadilla_61.png', 'fresadilla_63.png', 'fresadilla_62.png', 'fresadilla_64.png', 'fresadilla_65.png', 'fresadilla_66.png', 'fresadilla_68.png', 'fresadilla_67.png', 'fresadilla_69.png', 'fresadilla_7.png', 'fresadilla_70.png', 'fresadilla_71.png', 'fresadilla_72.png', 'fresadilla_73.png', 'fresadilla_74.png', 'fresadilla_75.png', 'fresadilla_76.png', 'fresadilla_8.png', 'fresadilla_9.png', 'pera_anjou_1.png', 'pera_anjou_10.png', 'pera_anjou_100.png', 'pera_anjou_101.png', 'pera_anjou_102.png', 'pera_anjou_103.png', 'pera_anjou_104.png', 'pera_anjou_105.png', 'pera_anjou_106.png', 'pera_anjou_107.png', 'pera_anjou_108.png', 'pera_anjou_109.png', 'pera_anjou_11.png', 'pera_anjou_110.png', 'pera_anjou_111.png', 'pera_anjou_112.png', 'pera_anjou_113.png', 'pera_anjou_114.png', 'pera_anjou_115.png', 'pera_anjou_116.png', 'pera_anjou_117.png', 'pera_anjou_118.png', 'pera_anjou_119.png', 'pera_anjou_12.png', 'pera_anjou_120.png', 'pera_anjou_121.png', 'pera_anjou_122.png', 'pera_anjou_123.png', 'pera_anjou_124.png', 'pera_anjou_125.png', 'pera_anjou_126.png', 'pera_anjou_127.png', 'pera_anjou_128.png', 'pera_anjou_129.png', 'pera_anjou_13.png', 'pera_anjou_130.png', 'pera_anjou_131.png', 'pera_anjou_132.png', 'pera_anjou_133.png', 'pera_anjou_134.png', 'pera_anjou_135.png', 'pera_anjou_136.png', 'pera_anjou_137.png', 'pera_anjou_138.png', 'pera_anjou_139.png', 'pera_anjou_14.png', 'pera_anjou_140.png', 'pera_anjou_141.png', 'pera_anjou_142.png', 'pera_anjou_143.png', 'pera_anjou_144.png', 'pera_anjou_145.png', 'pera_anjou_146.png', 'pera_anjou_147.png', 'pera_anjou_148.png', 'pera_anjou_149.png', 'pera_anjou_15.png', 'pera_anjou_150.png', 'pera_anjou_151.png', 'pera_anjou_152.png', 'pera_anjou_153.png', 'pera_anjou_154.png', 'pera_anjou_155.png', 'pera_anjou_156.png', 'pera_anjou_157.png', 'pera_anjou_158.png', 'pera_anjou_159.png', 'pera_anjou_16.png', 'pera_anjou_160.png', 'pera_anjou_161.png', 'pera_anjou_162.png', 'pera_anjou_163.png', 'pera_anjou_164.png', 'pera_anjou_165.png', 'pera_anjou_166.png', 'pera_anjou_167.png', 'pera_anjou_168.png', 'pera_anjou_169.png', 'pera_anjou_17.png', 'pera_anjou_170.png', 'pera_anjou_171.png', 'pera_anjou_172.png', 'pera_anjou_173.png', 'pera_anjou_174.png', 'pera_anjou_175.png', 'pera_anjou_176.png', 'pera_anjou_177.png', 'pera_anjou_178.png', 'pera_anjou_179.png', 'pera_anjou_18.png', 'pera_anjou_180.png', 'pera_anjou_181.png', 'pera_anjou_182.png', 'pera_anjou_183.png', 'pera_anjou_184.png', 'pera_anjou_185.png', 'pera_anjou_186.png', 'pera_anjou_187.png', 'pera_anjou_188.png', 'pera_anjou_189.png', 'pera_anjou_19.png', 'pera_anjou_190.png', 'pera_anjou_191.png', 'pera_anjou_192.png', 'pera_anjou_193.png', 'pera_anjou_194.png', 'pera_anjou_195.png', 'pera_anjou_196.png', 'pera_anjou_197.png', 'pera_anjou_198.png', 'pera_anjou_199.png', 'pera_anjou_2.png', 'pera_anjou_20.png', 'pera_anjou_200.png', 'pera_anjou_201.png', 'pera_anjou_202.png', 'pera_anjou_203.png', 'pera_anjou_204.png', 'pera_anjou_205.png', 'pera_anjou_206.png', 'pera_anjou_207.png', 'pera_anjou_208.png', 'pera_anjou_209.png', 'pera_anjou_21.png', 'pera_anjou_210.png', 'pera_anjou_211.png', 'pera_anjou_212.png', 'pera_anjou_213.png', 'pera_anjou_214.png', 'pera_anjou_215.png', 'pera_anjou_216.png', 'pera_anjou_217.png', 'pera_anjou_218.png', 'pera_anjou_219.png', 'pera_anjou_22.png', 'pera_anjou_220.png', 'pera_anjou_221.png', 'pera_anjou_222.png', 'pera_anjou_223.png', 'pera_anjou_224.png', 'pera_anjou_225.png', 'pera_anjou_226.png', 'pera_anjou_227.png', 'pera_anjou_228.png', 'pera_anjou_229.png', 'pera_anjou_23.png', 'pera_anjou_230.png', 'pera_anjou_231.png', 'pera_anjou_232.png', 'pera_anjou_233.png', 'pera_anjou_234.png', 'pera_anjou_235.png', 'pera_anjou_236.png', 'pera_anjou_237.png', 'pera_anjou_238.png', 'pera_anjou_239.png', 'pera_anjou_24.png', 'pera_anjou_240.png', 'pera_anjou_241.png', 'pera_anjou_242.png', 'pera_anjou_243.png', 'pera_anjou_244.png', 'pera_anjou_245.png', 'pera_anjou_246.png', 'pera_anjou_247.png', 'pera_anjou_248.png', 'pera_anjou_249.png', 'pera_anjou_25.png', 'pera_anjou_250.png', 'pera_anjou_251.png', 'pera_anjou_252.png', 'pera_anjou_253.png', 'pera_anjou_254.png', 'pera_anjou_255.png', 'pera_anjou_256.png', 'pera_anjou_257.png', 'pera_anjou_258.png', 'pera_anjou_259.png', 'pera_anjou_26.png', 'pera_anjou_260.png', 'pera_anjou_261.png', 'pera_anjou_262.png', 'pera_anjou_263.png', 'pera_anjou_264.png', 'pera_anjou_265.png', 'pera_anjou_266.png', 'pera_anjou_267.png', 'pera_anjou_268.png', 'pera_anjou_269.png', 'pera_anjou_27.png', 'pera_anjou_270.png', 'pera_anjou_271.png', 'pera_anjou_272.png', 'pera_anjou_273.png', 'pera_anjou_274.png', 'pera_anjou_275.png', 'pera_anjou_276.png', 'pera_anjou_277.png', 'pera_anjou_278.png', 'pera_anjou_279.png', 'pera_anjou_28.png', 'pera_anjou_280.png', 'pera_anjou_281.png', 'pera_anjou_282.png', 'pera_anjou_283.png', 'pera_anjou_284.png', 'pera_anjou_285.png', 'pera_anjou_286.png', 'pera_anjou_287.png', 'pera_anjou_288.png', 'pera_anjou_289.png', 'pera_anjou_29.png', 'pera_anjou_290.png', 'pera_anjou_291.png', 'pera_anjou_292.png', 'pera_anjou_293.png', 'pera_anjou_294.png', 'pera_anjou_295.png', 'pera_anjou_296.png', 'pera_anjou_297.png', 'pera_anjou_298.png', 'pera_anjou_299.png', 'pera_anjou_3.png', 'pera_anjou_30.png', 'pera_anjou_300.png', 'pera_anjou_301.png', 'pera_anjou_302.png', 'pera_anjou_303.png', 'pera_anjou_304.png', 'pera_anjou_305.png', 'pera_anjou_306.png', 'pera_anjou_307.png', 'pera_anjou_308.png', 'pera_anjou_309.png', 'pera_anjou_31.png', 'pera_anjou_310.png', 'pera_anjou_311.png', 'pera_anjou_312.png', 'pera_anjou_313.png', 'pera_anjou_314.png', 'pera_anjou_315.png', 'pera_anjou_316.png', 'pera_anjou_317.png', 'pera_anjou_318.png', 'pera_anjou_319.png', 'pera_anjou_32.png', 'pera_anjou_320.png', 'pera_anjou_321.png', 'pera_anjou_322.png', 'pera_anjou_323.png', 'pera_anjou_324.png', 'pera_anjou_325.png', 'pera_anjou_326.png', 'pera_anjou_327.png', 'pera_anjou_328.png', 'pera_anjou_329.png', 'pera_anjou_33.png', 'pera_anjou_330.png', 'pera_anjou_331.png', 'pera_anjou_332.png', 'pera_anjou_333.png', 'pera_anjou_334.png', 'pera_anjou_335.png', 'pera_anjou_336.png', 'pera_anjou_337.png', 'pera_anjou_338.png', 'pera_anjou_339.png', 'pera_anjou_34.png', 'pera_anjou_340.png', 'pera_anjou_341.png', 'pera_anjou_342.png', 'pera_anjou_343.png', 'pera_anjou_344.png', 'pera_anjou_345.png', 'pera_anjou_346.png', 'pera_anjou_347.png', 'pera_anjou_348.png', 'pera_anjou_349.png', 'pera_anjou_35.png', 'pera_anjou_350.png', 'pera_anjou_351.png', 'pera_anjou_352.png', 'pera_anjou_353.png', 'pera_anjou_354.png', 'pera_anjou_355.png', 'pera_anjou_356.png', 'pera_anjou_357.png', 'pera_anjou_358.png', 'pera_anjou_359.png', 'pera_anjou_36.png', 'pera_anjou_360.png', 'pera_anjou_361.png', 'pera_anjou_362.png', 'pera_anjou_363.png', 'pera_anjou_364.png', 'pera_anjou_365.png', 'pera_anjou_366.png', 'pera_anjou_367.png', 'pera_anjou_368.png', 'pera_anjou_369.png', 'pera_anjou_37.png', 'pera_anjou_370.png', 'pera_anjou_371.png', 'pera_anjou_372.png', 'pera_anjou_373.png', 'pera_anjou_374.png', 'pera_anjou_375.png', 'pera_anjou_376.png', 'pera_anjou_377.png', 'pera_anjou_378.png', 'pera_anjou_379.png', 'pera_anjou_38.png', 'pera_anjou_380.png', 'pera_anjou_381.png', 'pera_anjou_382.png', 'pera_anjou_383.png', 'pera_anjou_384.png', 'pera_anjou_385.png', 'pera_anjou_386.png', 'pera_anjou_387.png', 'pera_anjou_388.png', 'pera_anjou_389.png', 'pera_anjou_39.png', 'pera_anjou_390.png', 'pera_anjou_391.png', 'pera_anjou_392.png', 'pera_anjou_393.png', 'pera_anjou_394.png', 'pera_anjou_395.png', 'pera_anjou_396.png', 'pera_anjou_397.png', 'pera_anjou_398.png', 'pera_anjou_399.png', 'pera_anjou_4.png', 'pera_anjou_40.png', 'pera_anjou_400.png', 'pera_anjou_401.png', 'pera_anjou_402.png', 'pera_anjou_403.png', 'pera_anjou_404.png', 'pera_anjou_405.png', 'pera_anjou_406.png', 'pera_anjou_407.png', 'pera_anjou_408.png', 'pera_anjou_409.png', 'pera_anjou_41.png', 'pera_anjou_410.png', 'pera_anjou_411.png', 'pera_anjou_412.png', 'pera_anjou_413.png', 'pera_anjou_414.png', 'pera_anjou_415.png', 'pera_anjou_416.png', 'pera_anjou_417.png', 'pera_anjou_418.png', 'pera_anjou_419.png', 'pera_anjou_42.png', 'pera_anjou_420.png', 'pera_anjou_421.png', 'pera_anjou_422.png', 'pera_anjou_423.png', 'pera_anjou_424.png', 'pera_anjou_425.png', 'pera_anjou_426.png', 'pera_anjou_427.png', 'pera_anjou_428.png', 'pera_anjou_429.png', 'pera_anjou_43.png', 'pera_anjou_430.png', 'pera_anjou_431.png', 'pera_anjou_432.png', 'pera_anjou_433.png', 'pera_anjou_434.png', 'pera_anjou_435.png', 'pera_anjou_436.png', 'pera_anjou_437.png', 'pera_anjou_438.png', 'pera_anjou_439.png', 'pera_anjou_44.png', 'pera_anjou_440.png', 'pera_anjou_441.png', 'pera_anjou_442.png', 'pera_anjou_443.png', 'pera_anjou_444.png', 'pera_anjou_445.png', 'pera_anjou_446.png', 'pera_anjou_447.png', 'pera_anjou_448.png', 'pera_anjou_449.png', 'pera_anjou_45.png', 'pera_anjou_450.png', 'pera_anjou_451.png', 'pera_anjou_452.png', 'pera_anjou_453.png', 'pera_anjou_454.png', 'pera_anjou_455.png', 'pera_anjou_456.png', 'pera_anjou_457.png', 'pera_anjou_458.png', 'pera_anjou_459.png', 'pera_anjou_46.png', 'pera_anjou_460.png', 'pera_anjou_461.png', 'pera_anjou_462.png', 'pera_anjou_463.png', 'pera_anjou_464.png', 'pera_anjou_465.png', 'pera_anjou_466.png', 'pera_anjou_467.png', 'pera_anjou_468.png', 'pera_anjou_469.png', 'pera_anjou_47.png', 'pera_anjou_470.png', 'pera_anjou_471.png', 'pera_anjou_472.png', 'pera_anjou_473.png', 'pera_anjou_474.png', 'pera_anjou_475.png', 'pera_anjou_476.png', 'pera_anjou_477.png', 'pera_anjou_478.png', 'pera_anjou_479.png', 'pera_anjou_48.png', 'pera_anjou_480.png', 'pera_anjou_481.png', 'pera_anjou_482.png', 'pera_anjou_483.png', 'pera_anjou_484.png', 'pera_anjou_485.png', 'pera_anjou_486.png', 'pera_anjou_487.png', 'pera_anjou_488.png', 'pera_anjou_489.png', 'pera_anjou_49.png', 'pera_anjou_490.png', 'pera_anjou_491.png', 'pera_anjou_492.png', 'pera_anjou_493.png', 'pera_anjou_494.png', 'pera_anjou_495.png', 'pera_anjou_5.png', 'pera_anjou_50.png', 'pera_anjou_51.png', 'pera_anjou_52.png', 'pera_anjou_53.png', 'pera_anjou_54.png', 'pera_anjou_55.png', 'pera_anjou_56.png', 'pera_anjou_57.png', 'pera_anjou_58.png', 'pera_anjou_59.png', 'pera_anjou_6.png', 'pera_anjou_60.png', 'pera_anjou_61.png', 'pera_anjou_62.png', 'pera_anjou_63.png', 'pera_anjou_64.png', 'pera_anjou_65.png', 'pera_anjou_66.png', 'pera_anjou_67.png', 'pera_anjou_68.png', 'pera_anjou_69.png', 'pera_anjou_7.png', 'pera_anjou_70.png', 'pera_anjou_71.png', 'pera_anjou_72.png', 'pera_anjou_73.png', 'pera_anjou_74.png', 'pera_anjou_75.png', 'pera_anjou_76.png', 'pera_anjou_77.png', 'pera_anjou_78.png', 'pera_anjou_79.png', 'pera_anjou_8.png', 'pera_anjou_80.png', 'pera_anjou_81.png', 'pera_anjou_82.png', 'pera_anjou_83.png', 'pera_anjou_84.png', 'pera_anjou_85.png', 'pera_anjou_86.png', 'pera_anjou_87.png', 'pera_anjou_88.png', 'pera_anjou_89.png', 'pera_anjou_9.png', 'pera_anjou_90.png', 'pera_anjou_91.png', 'pera_anjou_92.png', 'pera_anjou_93.png', 'pera_anjou_94.png', 'pera_anjou_95.png', 'pera_anjou_96.png', 'pera_anjou_97.png', 'pera_anjou_98.png', 'pera_anjou_99.png', 'golden_1.png', 'golden_10.png', 'golden_100.png', 'golden_101.png', 'golden_102.png', 'golden_103.png', 'golden_104.png', 'golden_105.png', 'golden_106.png', 'golden_107.png', 'golden_108.png', 'golden_109.png', 'golden_11.png', 'golden_110.png', 'golden_111.png', 'golden_112.png', 'golden_113.png', 'golden_114.png', 'golden_115.png', 'golden_116.png', 'golden_117.png', 'golden_118.png', 'golden_119.png', 'golden_12.png', 'golden_120.png', 'golden_121.png', 'golden_122.png', 'golden_123.png', 'golden_124.png', 'golden_125.png', 'golden_126.png', 'golden_127.png', 'golden_128.png', 'golden_129.png', 'golden_13.png', 'golden_130.png', 'golden_131.png', 'golden_132.png', 'golden_133.png', 'golden_134.png', 'golden_135.png', 'golden_136.png', 'golden_137.png', 'golden_138.png', 'golden_139.png', 'golden_14.png', 'golden_140.png', 'golden_141.png', 'golden_142.png', 'golden_143.png', 'golden_144.png', 'golden_145.png', 'golden_146.png', 'golden_147.png', 'golden_148.png', 'golden_149.png', 'golden_15.png', 'golden_150.png', 'golden_151.png', 'golden_152.png', 'golden_153.png', 'golden_154.png', 'golden_155.png', 'golden_156.png', 'golden_157.png', 'golden_158.png', 'golden_159.png', 'golden_16.png', 'golden_160.png', 'golden_161.png', 'golden_162.png', 'golden_163.png', 'golden_164.png', 'golden_165.png', 'golden_166.png', 'golden_167.png', 'golden_168.png', 'golden_169.png', 'golden_17.png', 'golden_170.png', 'golden_171.png', 'golden_172.png', 'golden_173.png', 'golden_174.png', 'golden_175.png', 'golden_176.png', 'golden_177.png', 'golden_178.png', 'golden_179.png', 'golden_18.png', 'golden_180.png', 'golden_181.png', 'golden_182.png', 'golden_183.png', 'golden_184.png', 'golden_185.png', 'golden_186.png', 'golden_187.png', 'golden_188.png', 'golden_189.png', 'golden_19.png', 'golden_190.png', 'golden_191.png', 'golden_192.png', 'golden_193.png', 'golden_194.png', 'golden_195.png', 'golden_196.png', 'golden_197.png', 'golden_198.png', 'golden_199.png', 'golden_2.png', 'golden_20.png', 'golden_200.png', 'golden_201.png', 'golden_202.png', 'golden_203.png', 'golden_204.png', 'golden_205.png', 'golden_206.png', 'golden_207.png', 'golden_208.png', 'golden_209.png', 'golden_21.png', 'golden_210.png', 'golden_211.png', 'golden_212.png', 'golden_213.png', 'golden_214.png', 'golden_215.png', 'golden_216.png', 'golden_217.png', 'golden_218.png', 'golden_219.png', 'golden_22.png', 'golden_220.png', 'golden_221.png', 'golden_222.png', 'golden_223.png', 'golden_224.png', 'golden_225.png', 'golden_226.png', 'golden_227.png', 'golden_228.png', 'golden_229.png', 'golden_23.png', 'golden_230.png', 'golden_231.png', 'golden_232.png', 'golden_233.png', 'golden_234.png', 'golden_235.png', 'golden_236.png', 'golden_237.png', 'golden_238.png', 'golden_239.png', 'golden_24.png', 'golden_240.png', 'golden_241.png', 'golden_242.png', 'golden_243.png', 'golden_244.png', 'golden_245.png', 'golden_246.png', 'golden_247.png', 'golden_248.png', 'golden_249.png', 'golden_25.png', 'golden_250.png', 'golden_251.png', 'golden_252.png', 'golden_26.png', 'golden_27.png', 'golden_28.png', 'golden_29.png', 'golden_3.png', 'golden_30.png', 'golden_31.png', 'golden_32.png', 'golden_33.png', 'golden_34.png', 'golden_35.png', 'golden_36.png', 'golden_37.png', 'golden_38.png', 'golden_39.png', 'golden_4.png', 'golden_40.png', 'golden_41.png', 'golden_42.png', 'golden_43.png', 'golden_44.png', 'golden_45.png', 'golden_46.png', 'golden_47.png', 'golden_48.png', 'golden_49.png', 'golden_5.png', 'golden_50.png', 'golden_51.png', 'golden_52.png', 'golden_53.png', 'golden_54.png', 'golden_55.png', 'golden_56.png', 'golden_57.png', 'golden_58.png', 'golden_59.png', 'golden_6.png', 'golden_60.png', 'golden_61.png', 'golden_62.png', 'golden_63.png', 'golden_64.png', 'golden_65.png', 'golden_66.png', 'golden_67.png', 'golden_68.png', 'golden_69.png', 'golden_7.png', 'golden_70.png', 'golden_71.png', 'golden_72.png', 'golden_73.png', 'golden_74.png', 'golden_75.png', 'golden_76.png', 'golden_77.png', 'golden_78.png', 'golden_79.png', 'golden_8.png', 'golden_80.png', 'golden_81.png', 'golden_82.png', 'golden_83.png', 'golden_84.png', 'golden_85.png', 'golden_86.png', 'golden_87.png', 'golden_88.png', 'golden_89.png', 'golden_9.png', 'golden_90.png', 'golden_91.png', 'golden_92.png', 'golden_93.png', 'golden_94.png', 'golden_95.png', 'golden_96.png', 'golden_97.png', 'golden_98.png', 'golden_99.png', 'alcachofa_1.png', 'alcachofa_10.png', 'alcachofa_100.png', 'alcachofa_101.png', 'alcachofa_102.png', 'alcachofa_103.png', 'alcachofa_104.png', 'alcachofa_105.png', 'alcachofa_106.png', 'alcachofa_107.png', 'alcachofa_108.png', 'alcachofa_109.png', 'alcachofa_11.png', 'alcachofa_110.png', 'alcachofa_111.png', 'alcachofa_112.png', 'alcachofa_113.png', 'alcachofa_114.png', 'alcachofa_115.png', 'alcachofa_116.png', 'alcachofa_117.png', 'alcachofa_118.png', 'alcachofa_119.png', 'alcachofa_12.png', 'alcachofa_120.png', 'alcachofa_121.png', 'alcachofa_122.png', 'alcachofa_123.png', 'alcachofa_124.png', 'alcachofa_125.png', 'alcachofa_126.png', 'alcachofa_127.png', 'alcachofa_128.png', 'alcachofa_129.png', 'alcachofa_13.png', 'alcachofa_130.png', 'alcachofa_131.png', 'alcachofa_132.png', 'alcachofa_133.png', 'alcachofa_134.png', 'alcachofa_135.png', 'alcachofa_136.png', 'alcachofa_137.png', 'alcachofa_138.png', 'alcachofa_139.png', 'alcachofa_14.png', 'alcachofa_140.png', 'alcachofa_141.png', 'alcachofa_142.png', 'alcachofa_143.png', 'alcachofa_144.png', 'alcachofa_145.png', 'alcachofa_146.png', 'alcachofa_147.png', 'alcachofa_148.png', 'alcachofa_149.png', 'alcachofa_15.png', 'alcachofa_150.png', 'alcachofa_151.png', 'alcachofa_152.png', 'alcachofa_153.png', 'alcachofa_154.png', 'alcachofa_155.png', 'alcachofa_156.png', 'alcachofa_157.png', 'alcachofa_158.png', 'alcachofa_159.png', 'alcachofa_16.png', 'alcachofa_160.png', 'alcachofa_161.png', 'alcachofa_162.png', 'alcachofa_163.png', 'alcachofa_164.png', 'alcachofa_165.png', 'alcachofa_166.png', 'alcachofa_167.png', 'alcachofa_168.png', 'alcachofa_169.png', 'alcachofa_17.png', 'alcachofa_170.png', 'alcachofa_171.png', 'alcachofa_172.png', 'alcachofa_173.png', 'alcachofa_174.png', 'alcachofa_175.png', 'alcachofa_176.png', 'alcachofa_177.png', 'alcachofa_178.png', 'alcachofa_179.png', 'alcachofa_18.png', 'alcachofa_180.png', 'alcachofa_181.png', 'alcachofa_182.png', 'alcachofa_183.png', 'alcachofa_184.png', 'alcachofa_185.png', 'alcachofa_186.png', 'alcachofa_187.png', 'alcachofa_188.png', 'alcachofa_189.png', 'alcachofa_19.png', 'alcachofa_190.png', 'alcachofa_191.png', 'alcachofa_192.png', 'alcachofa_193.png', 'alcachofa_194.png', 'alcachofa_195.png', 'alcachofa_196.png', 'alcachofa_197.png', 'alcachofa_198.png', 'alcachofa_199.png', 'alcachofa_2.png', 'alcachofa_20.png', 'alcachofa_200.png', 'alcachofa_201.png', 'alcachofa_202.png', 'alcachofa_203.png', 'alcachofa_204.png', 'alcachofa_205.png', 'alcachofa_206.png', 'alcachofa_207.png', 'alcachofa_208.png', 'alcachofa_209.png', 'alcachofa_21.png', 'alcachofa_210.png', 'alcachofa_211.png', 'alcachofa_212.png', 'alcachofa_213.png', 'alcachofa_214.png', 'alcachofa_215.png', 'alcachofa_216.png', 'alcachofa_217.png', 'alcachofa_218.png', 'alcachofa_219.png', 'alcachofa_22.png', 'alcachofa_220.png', 'alcachofa_221.png', 'alcachofa_222.png', 'alcachofa_223.png', 'alcachofa_224.png', 'alcachofa_225.png', 'alcachofa_226.png', 'alcachofa_227.png', 'alcachofa_228.png', 'alcachofa_229.png', 'alcachofa_23.png', 'alcachofa_230.png', 'alcachofa_231.png', 'alcachofa_232.png', 'alcachofa_233.png', 'alcachofa_234.png', 'alcachofa_235.png', 'alcachofa_236.png', 'alcachofa_237.png', 'alcachofa_238.png', 'alcachofa_239.png', 'alcachofa_24.png', 'alcachofa_240.png', 'alcachofa_241.png', 'alcachofa_242.png', 'alcachofa_243.png', 'alcachofa_244.png', 'alcachofa_245.png', 'alcachofa_246.png', 'alcachofa_247.png', 'alcachofa_248.png', 'alcachofa_249.png', 'alcachofa_25.png', 'alcachofa_250.png', 'alcachofa_251.png', 'alcachofa_252.png', 'alcachofa_253.png', 'alcachofa_254.png', 'alcachofa_255.png', 'alcachofa_256.png', 'alcachofa_257.png', 'alcachofa_258.png', 'alcachofa_259.png', 'alcachofa_26.png', 'alcachofa_260.png', 'alcachofa_261.png', 'alcachofa_262.png', 'alcachofa_263.png', 'alcachofa_264.png', 'alcachofa_265.png', 'alcachofa_266.png', 'alcachofa_267.png', 'alcachofa_268.png', 'alcachofa_269.png', 'alcachofa_27.png', 'alcachofa_270.png', 'alcachofa_271.png', 'alcachofa_272.png', 'alcachofa_273.png', 'alcachofa_274.png', 'alcachofa_275.png', 'alcachofa_276.png', 'alcachofa_277.png', 'alcachofa_278.png', 'alcachofa_279.png', 'alcachofa_28.png', 'alcachofa_280.png', 'alcachofa_281.png', 'alcachofa_282.png', 'alcachofa_283.png', 'alcachofa_284.png', 'alcachofa_285.png', 'alcachofa_286.png', 'alcachofa_287.png', 'alcachofa_288.png', 'alcachofa_289.png', 'alcachofa_29.png', 'alcachofa_290.png', 'alcachofa_291.png', 'alcachofa_292.png', 'alcachofa_293.png', 'alcachofa_294.png', 'alcachofa_295.png', 'alcachofa_296.png', 'alcachofa_297.png', 'alcachofa_298.png', 'alcachofa_299.png', 'alcachofa_3.png', 'alcachofa_30.png', 'alcachofa_300.png', 'alcachofa_301.png', 'alcachofa_302.png', 'alcachofa_303.png', 'alcachofa_304.png', 'alcachofa_305.png', 'alcachofa_306.png', 'alcachofa_307.png', 'alcachofa_308.png', 'alcachofa_309.png', 'alcachofa_31.png', 'alcachofa_310.png', 'alcachofa_311.png', 'alcachofa_312.png', 'alcachofa_313.png', 'alcachofa_314.png', 'alcachofa_315.png', 'alcachofa_316.png', 'alcachofa_317.png', 'alcachofa_318.png', 'alcachofa_319.png', 'alcachofa_32.png', 'alcachofa_320.png', 'alcachofa_321.png', 'alcachofa_322.png', 'alcachofa_323.png', 'alcachofa_324.png', 'alcachofa_325.png', 'alcachofa_326.png', 'alcachofa_327.png', 'alcachofa_33.png', 'alcachofa_34.png', 'alcachofa_35.png', 'alcachofa_36.png', 'alcachofa_37.png', 'alcachofa_38.png', 'alcachofa_39.png', 'alcachofa_4.png', 'alcachofa_40.png', 'alcachofa_41.png', 'alcachofa_42.png', 'alcachofa_43.png', 'alcachofa_44.png', 'alcachofa_45.png', 'alcachofa_46.png', 'alcachofa_47.png', 'alcachofa_48.png', 'alcachofa_49.png', 'alcachofa_5.png', 'alcachofa_50.png', 'alcachofa_51.png', 'alcachofa_52.png', 'alcachofa_53.png', 'alcachofa_54.png', 'alcachofa_55.png', 'alcachofa_56.png', 'alcachofa_57.png', 'alcachofa_58.png', 'alcachofa_59.png', 'alcachofa_6.png', 'alcachofa_60.png', 'alcachofa_61.png', 'alcachofa_62.png', 'alcachofa_63.png', 'alcachofa_64.png', 'alcachofa_65.png', 'alcachofa_66.png', 'alcachofa_67.png', 'alcachofa_68.png', 'alcachofa_69.png', 'alcachofa_7.png', 'alcachofa_70.png', 'alcachofa_71.png', 'alcachofa_72.png', 'alcachofa_73.png', 'alcachofa_74.png', 'alcachofa_75.png', 'alcachofa_76.png', 'alcachofa_77.png', 'alcachofa_78.png', 'alcachofa_79.png', 'alcachofa_8.png', 'alcachofa_80.png', 'alcachofa_81.png', 'alcachofa_82.png', 'alcachofa_83.png', 'alcachofa_84.png', 'alcachofa_85.png', 'alcachofa_86.png', 'alcachofa_87.png', 'alcachofa_88.png', 'alcachofa_89.png', 'alcachofa_9.png', 'alcachofa_90.png', 'alcachofa_91.png', 'alcachofa_92.png', 'alcachofa_93.png', 'alcachofa_94.png', 'alcachofa_95.png', 'alcachofa_96.png', 'alcachofa_97.png', 'alcachofa_98.png', 'alcachofa_99.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbnFEYbqgZyc"
      },
      "source": [
        "If the loss does not lower significantly (at least 1e-6) then the training automatically stops and saves the last weights together with the neural network as \"**mbnv2.h5**\". This file can now be used for predictive inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJQm1fqd42x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd25a0b1-ab63-40d6-e346-84d80c9fbcb6"
      },
      "source": [
        "!python \"train.py\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-15 17:25:43.127535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "['acelga', 'alcachofa', 'espinaca', 'fresadilla', 'fresadilla2', 'golden', 'pera_anjou', 'pera_asiatica', 'pina_miel', 'saltillo', 'tomatillo']\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "2020-07-15 17:25:45.479659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-15 17:25:45.496968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.497753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-07-15 17:25:45.497810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 17:25:45.499656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 17:25:45.501458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 17:25:45.501830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 17:25:45.503569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 17:25:45.504613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 17:25:45.508375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 17:25:45.508554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.509445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.510295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-15 17:25:45.516310: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-15 17:25:45.516528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2349480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 17:25:45.516577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-15 17:25:45.572258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.573140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x73bf500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 17:25:45.573189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-07-15 17:25:45.573462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.574300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-07-15 17:25:45.574392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 17:25:45.574459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 17:25:45.574512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 17:25:45.574578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 17:25:45.574650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 17:25:45.574701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 17:25:45.574750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 17:25:45.574900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.575735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:45.576471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-15 17:25:45.576533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 17:25:46.005641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 17:25:46.005699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-07-15 17:25:46.005717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-07-15 17:25:46.005995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:46.006839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 17:25:46.007544: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-15 17:25:46.007600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10634 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Model)    (None, None, None, 1 2257984     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, None, 1 0           mobilenetv2_1.00_224[1][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 1280)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1280)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2560)         0           global_max_pooling2d[0][0]       \n",
            "                                                                 global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2560)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 11)           28171       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,286,155\n",
            "Trainable params: 2,252,043\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From train.py:59: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/150\n",
            "2020-07-15 17:26:35.252812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 17:26:36.691005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "76/76 [==============================] - ETA: 0s - loss: 1.0657 - binary_accuracy: 0.8430 \n",
            "Epoch 00001: val_loss improved from inf to 0.57018, saving model to fruit.h5\n",
            "76/76 [==============================] - 1905s 25s/step - loss: 1.0657 - binary_accuracy: 0.8430 - val_loss: 0.5702 - val_binary_accuracy: 0.8236 - lr: 1.0000e-04\n",
            "Epoch 2/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.3771 - binary_accuracy: 0.9194\n",
            "Epoch 00002: val_loss improved from 0.57018 to 0.46925, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 806ms/step - loss: 0.3771 - binary_accuracy: 0.9194 - val_loss: 0.4693 - val_binary_accuracy: 0.8563 - lr: 1.0000e-04\n",
            "Epoch 3/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.2353 - binary_accuracy: 0.9405\n",
            "Epoch 00003: val_loss improved from 0.46925 to 0.41426, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 807ms/step - loss: 0.2353 - binary_accuracy: 0.9405 - val_loss: 0.4143 - val_binary_accuracy: 0.8760 - lr: 1.0000e-04\n",
            "Epoch 4/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.1567 - binary_accuracy: 0.9548\n",
            "Epoch 00004: val_loss improved from 0.41426 to 0.30313, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 798ms/step - loss: 0.1567 - binary_accuracy: 0.9548 - val_loss: 0.3031 - val_binary_accuracy: 0.9063 - lr: 1.0000e-04\n",
            "Epoch 5/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.1201 - binary_accuracy: 0.9651\n",
            "Epoch 00005: val_loss improved from 0.30313 to 0.23683, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 785ms/step - loss: 0.1201 - binary_accuracy: 0.9651 - val_loss: 0.2368 - val_binary_accuracy: 0.9266 - lr: 1.0000e-04\n",
            "Epoch 6/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.1009 - binary_accuracy: 0.9697\n",
            "Epoch 00006: val_loss improved from 0.23683 to 0.18193, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 806ms/step - loss: 0.1009 - binary_accuracy: 0.9697 - val_loss: 0.1819 - val_binary_accuracy: 0.9368 - lr: 1.0000e-04\n",
            "Epoch 7/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0742 - binary_accuracy: 0.9762\n",
            "Epoch 00007: val_loss improved from 0.18193 to 0.13369, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 818ms/step - loss: 0.0742 - binary_accuracy: 0.9762 - val_loss: 0.1337 - val_binary_accuracy: 0.9565 - lr: 1.0000e-04\n",
            "Epoch 8/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0560 - binary_accuracy: 0.9811\n",
            "Epoch 00008: val_loss improved from 0.13369 to 0.10514, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 786ms/step - loss: 0.0560 - binary_accuracy: 0.9811 - val_loss: 0.1051 - val_binary_accuracy: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 9/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0614 - binary_accuracy: 0.9807\n",
            "Epoch 00009: val_loss improved from 0.10514 to 0.07845, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 811ms/step - loss: 0.0614 - binary_accuracy: 0.9807 - val_loss: 0.0784 - val_binary_accuracy: 0.9734 - lr: 1.0000e-04\n",
            "Epoch 10/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0445 - binary_accuracy: 0.9850\n",
            "Epoch 00010: val_loss improved from 0.07845 to 0.05768, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 804ms/step - loss: 0.0445 - binary_accuracy: 0.9850 - val_loss: 0.0577 - val_binary_accuracy: 0.9806 - lr: 1.0000e-04\n",
            "Epoch 11/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0416 - binary_accuracy: 0.9857\n",
            "Epoch 00011: val_loss improved from 0.05768 to 0.04917, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 821ms/step - loss: 0.0416 - binary_accuracy: 0.9857 - val_loss: 0.0492 - val_binary_accuracy: 0.9824 - lr: 1.0000e-04\n",
            "Epoch 12/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0375 - binary_accuracy: 0.9871\n",
            "Epoch 00012: val_loss improved from 0.04917 to 0.04092, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 817ms/step - loss: 0.0375 - binary_accuracy: 0.9871 - val_loss: 0.0409 - val_binary_accuracy: 0.9865 - lr: 1.0000e-04\n",
            "Epoch 13/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0287 - binary_accuracy: 0.9904\n",
            "Epoch 00013: val_loss improved from 0.04092 to 0.04009, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 791ms/step - loss: 0.0287 - binary_accuracy: 0.9904 - val_loss: 0.0401 - val_binary_accuracy: 0.9870 - lr: 1.0000e-04\n",
            "Epoch 14/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0224 - binary_accuracy: 0.9921\n",
            "Epoch 00014: val_loss improved from 0.04009 to 0.03601, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 788ms/step - loss: 0.0224 - binary_accuracy: 0.9921 - val_loss: 0.0360 - val_binary_accuracy: 0.9871 - lr: 1.0000e-04\n",
            "Epoch 15/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0188 - binary_accuracy: 0.9930\n",
            "Epoch 00015: val_loss improved from 0.03601 to 0.02713, saving model to fruit.h5\n",
            "76/76 [==============================] - 59s 783ms/step - loss: 0.0188 - binary_accuracy: 0.9930 - val_loss: 0.0271 - val_binary_accuracy: 0.9901 - lr: 1.0000e-04\n",
            "Epoch 16/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0230 - binary_accuracy: 0.9918\n",
            "Epoch 00016: val_loss did not improve from 0.02713\n",
            "76/76 [==============================] - 61s 798ms/step - loss: 0.0230 - binary_accuracy: 0.9918 - val_loss: 0.0272 - val_binary_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 17/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0181 - binary_accuracy: 0.9935\n",
            "Epoch 00017: val_loss improved from 0.02713 to 0.02257, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 804ms/step - loss: 0.0181 - binary_accuracy: 0.9935 - val_loss: 0.0226 - val_binary_accuracy: 0.9924 - lr: 1.0000e-04\n",
            "Epoch 18/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0228 - binary_accuracy: 0.9921\n",
            "Epoch 00018: val_loss improved from 0.02257 to 0.02045, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 793ms/step - loss: 0.0228 - binary_accuracy: 0.9921 - val_loss: 0.0205 - val_binary_accuracy: 0.9927 - lr: 1.0000e-04\n",
            "Epoch 19/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0157 - binary_accuracy: 0.9946\n",
            "Epoch 00019: val_loss improved from 0.02045 to 0.01749, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 793ms/step - loss: 0.0157 - binary_accuracy: 0.9946 - val_loss: 0.0175 - val_binary_accuracy: 0.9939 - lr: 1.0000e-04\n",
            "Epoch 20/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0155 - binary_accuracy: 0.9947\n",
            "Epoch 00020: val_loss did not improve from 0.01749\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0155 - binary_accuracy: 0.9947 - val_loss: 0.0207 - val_binary_accuracy: 0.9927 - lr: 1.0000e-04\n",
            "Epoch 21/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0177 - binary_accuracy: 0.9939\n",
            "Epoch 00021: val_loss did not improve from 0.01749\n",
            "76/76 [==============================] - 60s 783ms/step - loss: 0.0177 - binary_accuracy: 0.9939 - val_loss: 0.0225 - val_binary_accuracy: 0.9921 - lr: 1.0000e-04\n",
            "Epoch 22/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0124 - binary_accuracy: 0.9959\n",
            "Epoch 00022: val_loss did not improve from 0.01749\n",
            "76/76 [==============================] - 60s 789ms/step - loss: 0.0124 - binary_accuracy: 0.9959 - val_loss: 0.0206 - val_binary_accuracy: 0.9928 - lr: 1.0000e-04\n",
            "Epoch 23/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0142 - binary_accuracy: 0.9944\n",
            "Epoch 00023: val_loss improved from 0.01749 to 0.01246, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 800ms/step - loss: 0.0142 - binary_accuracy: 0.9944 - val_loss: 0.0125 - val_binary_accuracy: 0.9951 - lr: 1.0000e-04\n",
            "Epoch 24/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0149 - binary_accuracy: 0.9947\n",
            "Epoch 00024: val_loss improved from 0.01246 to 0.01060, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 804ms/step - loss: 0.0149 - binary_accuracy: 0.9947 - val_loss: 0.0106 - val_binary_accuracy: 0.9960 - lr: 1.0000e-04\n",
            "Epoch 25/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0120 - binary_accuracy: 0.9957\n",
            "Epoch 00025: val_loss did not improve from 0.01060\n",
            "76/76 [==============================] - 58s 763ms/step - loss: 0.0120 - binary_accuracy: 0.9957 - val_loss: 0.0137 - val_binary_accuracy: 0.9954 - lr: 1.0000e-04\n",
            "Epoch 26/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0113 - binary_accuracy: 0.9957\n",
            "Epoch 00026: val_loss did not improve from 0.01060\n",
            "76/76 [==============================] - 60s 784ms/step - loss: 0.0113 - binary_accuracy: 0.9957 - val_loss: 0.0114 - val_binary_accuracy: 0.9955 - lr: 1.0000e-04\n",
            "Epoch 27/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0114 - binary_accuracy: 0.9963\n",
            "Epoch 00027: val_loss did not improve from 0.01060\n",
            "76/76 [==============================] - 60s 792ms/step - loss: 0.0114 - binary_accuracy: 0.9963 - val_loss: 0.0114 - val_binary_accuracy: 0.9957 - lr: 1.0000e-04\n",
            "Epoch 28/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0084 - binary_accuracy: 0.9972\n",
            "Epoch 00028: val_loss improved from 0.01060 to 0.00854, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 783ms/step - loss: 0.0084 - binary_accuracy: 0.9972 - val_loss: 0.0085 - val_binary_accuracy: 0.9969 - lr: 1.0000e-04\n",
            "Epoch 29/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0090 - binary_accuracy: 0.9967\n",
            "Epoch 00029: val_loss improved from 0.00854 to 0.00798, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 798ms/step - loss: 0.0090 - binary_accuracy: 0.9967 - val_loss: 0.0080 - val_binary_accuracy: 0.9970 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0078 - binary_accuracy: 0.9976\n",
            "Epoch 00030: val_loss improved from 0.00798 to 0.00622, saving model to fruit.h5\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0078 - binary_accuracy: 0.9976 - val_loss: 0.0062 - val_binary_accuracy: 0.9978 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0065 - binary_accuracy: 0.9978\n",
            "Epoch 00031: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 781ms/step - loss: 0.0065 - binary_accuracy: 0.9978 - val_loss: 0.0081 - val_binary_accuracy: 0.9973 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0066 - binary_accuracy: 0.9973\n",
            "Epoch 00032: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 774ms/step - loss: 0.0066 - binary_accuracy: 0.9973 - val_loss: 0.0081 - val_binary_accuracy: 0.9976 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0054 - binary_accuracy: 0.9983\n",
            "Epoch 00033: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 775ms/step - loss: 0.0054 - binary_accuracy: 0.9983 - val_loss: 0.0100 - val_binary_accuracy: 0.9966 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0117 - binary_accuracy: 0.9963\n",
            "Epoch 00034: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 58s 762ms/step - loss: 0.0117 - binary_accuracy: 0.9963 - val_loss: 0.0274 - val_binary_accuracy: 0.9916 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0150 - binary_accuracy: 0.9955\n",
            "Epoch 00035: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 60s 794ms/step - loss: 0.0150 - binary_accuracy: 0.9955 - val_loss: 0.0288 - val_binary_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0107 - binary_accuracy: 0.9967\n",
            "Epoch 00036: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 58s 761ms/step - loss: 0.0107 - binary_accuracy: 0.9967 - val_loss: 0.0193 - val_binary_accuracy: 0.9939 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0096 - binary_accuracy: 0.9967\n",
            "Epoch 00037: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 778ms/step - loss: 0.0096 - binary_accuracy: 0.9967 - val_loss: 0.0129 - val_binary_accuracy: 0.9961 - lr: 1.0000e-04\n",
            "Epoch 38/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0093 - binary_accuracy: 0.9967\n",
            "Epoch 00038: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 60s 790ms/step - loss: 0.0093 - binary_accuracy: 0.9967 - val_loss: 0.0143 - val_binary_accuracy: 0.9957 - lr: 1.0000e-04\n",
            "Epoch 39/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0061 - binary_accuracy: 0.9978\n",
            "Epoch 00039: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 58s 768ms/step - loss: 0.0061 - binary_accuracy: 0.9978 - val_loss: 0.0077 - val_binary_accuracy: 0.9976 - lr: 1.0000e-04\n",
            "Epoch 40/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0111 - binary_accuracy: 0.9973\n",
            "Epoch 00040: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 777ms/step - loss: 0.0111 - binary_accuracy: 0.9973 - val_loss: 0.0278 - val_binary_accuracy: 0.9901 - lr: 1.0000e-04\n",
            "Epoch 41/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0107 - binary_accuracy: 0.9966\n",
            "Epoch 00041: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 60s 793ms/step - loss: 0.0107 - binary_accuracy: 0.9966 - val_loss: 0.0202 - val_binary_accuracy: 0.9927 - lr: 1.0000e-05\n",
            "Epoch 42/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0104 - binary_accuracy: 0.9965\n",
            "Epoch 00042: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 780ms/step - loss: 0.0104 - binary_accuracy: 0.9965 - val_loss: 0.0149 - val_binary_accuracy: 0.9952 - lr: 1.0000e-05\n",
            "Epoch 43/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0072 - binary_accuracy: 0.9975\n",
            "Epoch 00043: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 61s 800ms/step - loss: 0.0072 - binary_accuracy: 0.9975 - val_loss: 0.0111 - val_binary_accuracy: 0.9964 - lr: 1.0000e-05\n",
            "Epoch 44/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0092 - binary_accuracy: 0.9972\n",
            "Epoch 00044: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0092 - binary_accuracy: 0.9972 - val_loss: 0.0082 - val_binary_accuracy: 0.9972 - lr: 1.0000e-05\n",
            "Epoch 45/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0056 - binary_accuracy: 0.9983\n",
            "Epoch 00045: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 60s 786ms/step - loss: 0.0056 - binary_accuracy: 0.9983 - val_loss: 0.0076 - val_binary_accuracy: 0.9975 - lr: 1.0000e-05\n",
            "Epoch 46/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0070 - binary_accuracy: 0.9975\n",
            "Epoch 00046: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 59s 783ms/step - loss: 0.0070 - binary_accuracy: 0.9975 - val_loss: 0.0071 - val_binary_accuracy: 0.9979 - lr: 1.0000e-05\n",
            "Epoch 47/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0049 - binary_accuracy: 0.9983\n",
            "Epoch 00047: val_loss did not improve from 0.00622\n",
            "76/76 [==============================] - 58s 757ms/step - loss: 0.0049 - binary_accuracy: 0.9983 - val_loss: 0.0065 - val_binary_accuracy: 0.9981 - lr: 1.0000e-05\n",
            "Epoch 48/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0071 - binary_accuracy: 0.9977\n",
            "Epoch 00048: val_loss improved from 0.00622 to 0.00588, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 799ms/step - loss: 0.0071 - binary_accuracy: 0.9977 - val_loss: 0.0059 - val_binary_accuracy: 0.9982 - lr: 1.0000e-05\n",
            "Epoch 49/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0064 - binary_accuracy: 0.9981\n",
            "Epoch 00049: val_loss did not improve from 0.00588\n",
            "76/76 [==============================] - 59s 770ms/step - loss: 0.0064 - binary_accuracy: 0.9981 - val_loss: 0.0061 - val_binary_accuracy: 0.9982 - lr: 1.0000e-05\n",
            "Epoch 50/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0057 - binary_accuracy: 0.9983\n",
            "Epoch 00050: val_loss improved from 0.00588 to 0.00555, saving model to fruit.h5\n",
            "76/76 [==============================] - 59s 775ms/step - loss: 0.0057 - binary_accuracy: 0.9983 - val_loss: 0.0055 - val_binary_accuracy: 0.9982 - lr: 1.0000e-05\n",
            "Epoch 51/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0054 - binary_accuracy: 0.9981\n",
            "Epoch 00051: val_loss did not improve from 0.00555\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0054 - binary_accuracy: 0.9981 - val_loss: 0.0056 - val_binary_accuracy: 0.9981 - lr: 1.0000e-05\n",
            "Epoch 52/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0062 - binary_accuracy: 0.9976\n",
            "Epoch 00052: val_loss improved from 0.00555 to 0.00491, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 802ms/step - loss: 0.0062 - binary_accuracy: 0.9976 - val_loss: 0.0049 - val_binary_accuracy: 0.9984 - lr: 1.0000e-05\n",
            "Epoch 53/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0039 - binary_accuracy: 0.9986\n",
            "Epoch 00053: val_loss improved from 0.00491 to 0.00474, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 813ms/step - loss: 0.0039 - binary_accuracy: 0.9986 - val_loss: 0.0047 - val_binary_accuracy: 0.9987 - lr: 1.0000e-05\n",
            "Epoch 54/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0047 - binary_accuracy: 0.9985\n",
            "Epoch 00054: val_loss improved from 0.00474 to 0.00459, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 788ms/step - loss: 0.0047 - binary_accuracy: 0.9985 - val_loss: 0.0046 - val_binary_accuracy: 0.9987 - lr: 1.0000e-05\n",
            "Epoch 55/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0034 - binary_accuracy: 0.9989\n",
            "Epoch 00055: val_loss improved from 0.00459 to 0.00448, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 796ms/step - loss: 0.0034 - binary_accuracy: 0.9989 - val_loss: 0.0045 - val_binary_accuracy: 0.9987 - lr: 1.0000e-05\n",
            "Epoch 56/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0047 - binary_accuracy: 0.9984\n",
            "Epoch 00056: val_loss improved from 0.00448 to 0.00442, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 802ms/step - loss: 0.0047 - binary_accuracy: 0.9984 - val_loss: 0.0044 - val_binary_accuracy: 0.9985 - lr: 1.0000e-05\n",
            "Epoch 57/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0068 - binary_accuracy: 0.9981\n",
            "Epoch 00057: val_loss improved from 0.00442 to 0.00416, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 822ms/step - loss: 0.0068 - binary_accuracy: 0.9981 - val_loss: 0.0042 - val_binary_accuracy: 0.9985 - lr: 1.0000e-05\n",
            "Epoch 58/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0041 - binary_accuracy: 0.9987\n",
            "Epoch 00058: val_loss did not improve from 0.00416\n",
            "76/76 [==============================] - 61s 797ms/step - loss: 0.0041 - binary_accuracy: 0.9987 - val_loss: 0.0044 - val_binary_accuracy: 0.9985 - lr: 1.0000e-05\n",
            "Epoch 59/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0032 - binary_accuracy: 0.9990\n",
            "Epoch 00059: val_loss did not improve from 0.00416\n",
            "76/76 [==============================] - 59s 780ms/step - loss: 0.0032 - binary_accuracy: 0.9990 - val_loss: 0.0047 - val_binary_accuracy: 0.9985 - lr: 1.0000e-05\n",
            "Epoch 60/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0037 - binary_accuracy: 0.9985\n",
            "Epoch 00060: val_loss did not improve from 0.00416\n",
            "76/76 [==============================] - 60s 786ms/step - loss: 0.0037 - binary_accuracy: 0.9985 - val_loss: 0.0044 - val_binary_accuracy: 0.9987 - lr: 1.0000e-05\n",
            "Epoch 61/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0041 - binary_accuracy: 0.9986\n",
            "Epoch 00061: val_loss improved from 0.00416 to 0.00402, saving model to fruit.h5\n",
            "76/76 [==============================] - 59s 779ms/step - loss: 0.0041 - binary_accuracy: 0.9986 - val_loss: 0.0040 - val_binary_accuracy: 0.9987 - lr: 1.0000e-05\n",
            "Epoch 62/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0040 - binary_accuracy: 0.9985\n",
            "Epoch 00062: val_loss improved from 0.00402 to 0.00370, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 784ms/step - loss: 0.0040 - binary_accuracy: 0.9985 - val_loss: 0.0037 - val_binary_accuracy: 0.9988 - lr: 1.0000e-05\n",
            "Epoch 63/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0078 - binary_accuracy: 0.9982\n",
            "Epoch 00063: val_loss improved from 0.00370 to 0.00349, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 812ms/step - loss: 0.0078 - binary_accuracy: 0.9982 - val_loss: 0.0035 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 64/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0035 - binary_accuracy: 0.9986\n",
            "Epoch 00064: val_loss did not improve from 0.00349\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0035 - binary_accuracy: 0.9986 - val_loss: 0.0035 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 65/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0047 - binary_accuracy: 0.9985\n",
            "Epoch 00065: val_loss improved from 0.00349 to 0.00319, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 802ms/step - loss: 0.0047 - binary_accuracy: 0.9985 - val_loss: 0.0032 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 66/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0064 - binary_accuracy: 0.9981\n",
            "Epoch 00066: val_loss did not improve from 0.00319\n",
            "76/76 [==============================] - 59s 773ms/step - loss: 0.0064 - binary_accuracy: 0.9981 - val_loss: 0.0032 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 67/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0047 - binary_accuracy: 0.9984\n",
            "Epoch 00067: val_loss did not improve from 0.00319\n",
            "76/76 [==============================] - 60s 790ms/step - loss: 0.0047 - binary_accuracy: 0.9984 - val_loss: 0.0033 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 68/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0041 - binary_accuracy: 0.9989\n",
            "Epoch 00068: val_loss improved from 0.00319 to 0.00305, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 797ms/step - loss: 0.0041 - binary_accuracy: 0.9989 - val_loss: 0.0030 - val_binary_accuracy: 0.9993 - lr: 1.0000e-05\n",
            "Epoch 69/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0043 - binary_accuracy: 0.9987\n",
            "Epoch 00069: val_loss did not improve from 0.00305\n",
            "76/76 [==============================] - 60s 790ms/step - loss: 0.0043 - binary_accuracy: 0.9987 - val_loss: 0.0031 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 70/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0048 - binary_accuracy: 0.9986\n",
            "Epoch 00070: val_loss did not improve from 0.00305\n",
            "76/76 [==============================] - 60s 786ms/step - loss: 0.0048 - binary_accuracy: 0.9986 - val_loss: 0.0031 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 71/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0034 - binary_accuracy: 0.9988\n",
            "Epoch 00071: val_loss improved from 0.00305 to 0.00302, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 808ms/step - loss: 0.0034 - binary_accuracy: 0.9988 - val_loss: 0.0030 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 72/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0037 - binary_accuracy: 0.9989\n",
            "Epoch 00072: val_loss improved from 0.00302 to 0.00296, saving model to fruit.h5\n",
            "76/76 [==============================] - 62s 820ms/step - loss: 0.0037 - binary_accuracy: 0.9989 - val_loss: 0.0030 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 73/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0032 - binary_accuracy: 0.9989\n",
            "Epoch 00073: val_loss did not improve from 0.00296\n",
            "76/76 [==============================] - 60s 793ms/step - loss: 0.0032 - binary_accuracy: 0.9989 - val_loss: 0.0030 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 74/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0040 - binary_accuracy: 0.9988\n",
            "Epoch 00074: val_loss did not improve from 0.00296\n",
            "76/76 [==============================] - 61s 799ms/step - loss: 0.0040 - binary_accuracy: 0.9988 - val_loss: 0.0030 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 75/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0042 - binary_accuracy: 0.9986\n",
            "Epoch 00075: val_loss did not improve from 0.00296\n",
            "76/76 [==============================] - 61s 797ms/step - loss: 0.0042 - binary_accuracy: 0.9986 - val_loss: 0.0031 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 76/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0041 - binary_accuracy: 0.9989\n",
            "Epoch 00076: val_loss improved from 0.00296 to 0.00291, saving model to fruit.h5\n",
            "76/76 [==============================] - 60s 792ms/step - loss: 0.0041 - binary_accuracy: 0.9989 - val_loss: 0.0029 - val_binary_accuracy: 0.9990 - lr: 1.0000e-05\n",
            "Epoch 77/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0038 - binary_accuracy: 0.9984\n",
            "Epoch 00077: val_loss did not improve from 0.00291\n",
            "76/76 [==============================] - 60s 788ms/step - loss: 0.0038 - binary_accuracy: 0.9984 - val_loss: 0.0029 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 78/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0036 - binary_accuracy: 0.9986\n",
            "Epoch 00078: val_loss did not improve from 0.00291\n",
            "76/76 [==============================] - 61s 806ms/step - loss: 0.0036 - binary_accuracy: 0.9986 - val_loss: 0.0030 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 79/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0031 - binary_accuracy: 0.9989\n",
            "Epoch 00079: val_loss improved from 0.00291 to 0.00290, saving model to fruit.h5\n",
            "76/76 [==============================] - 61s 800ms/step - loss: 0.0031 - binary_accuracy: 0.9989 - val_loss: 0.0029 - val_binary_accuracy: 0.9993 - lr: 1.0000e-05\n",
            "Epoch 80/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0038 - binary_accuracy: 0.9987\n",
            "Epoch 00080: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 787ms/step - loss: 0.0038 - binary_accuracy: 0.9987 - val_loss: 0.0031 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 81/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0044 - binary_accuracy: 0.9984\n",
            "Epoch 00081: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0044 - binary_accuracy: 0.9984 - val_loss: 0.0033 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 82/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0035 - binary_accuracy: 0.9991\n",
            "Epoch 00082: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0035 - binary_accuracy: 0.9991 - val_loss: 0.0032 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 83/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0034 - binary_accuracy: 0.9989\n",
            "Epoch 00083: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 791ms/step - loss: 0.0034 - binary_accuracy: 0.9989 - val_loss: 0.0032 - val_binary_accuracy: 0.9991 - lr: 1.0000e-05\n",
            "Epoch 84/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0035 - binary_accuracy: 0.9988\n",
            "Epoch 00084: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 792ms/step - loss: 0.0035 - binary_accuracy: 0.9988 - val_loss: 0.0035 - val_binary_accuracy: 0.9990 - lr: 1.0000e-05\n",
            "Epoch 85/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0026 - binary_accuracy: 0.9988\n",
            "Epoch 00085: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 779ms/step - loss: 0.0026 - binary_accuracy: 0.9988 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-05\n",
            "Epoch 86/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0026 - binary_accuracy: 0.9993\n",
            "Epoch 00086: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 780ms/step - loss: 0.0026 - binary_accuracy: 0.9993 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-05\n",
            "Epoch 87/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0022 - binary_accuracy: 0.9993\n",
            "Epoch 00087: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0022 - binary_accuracy: 0.9993 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 88/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0027 - binary_accuracy: 0.9990\n",
            "Epoch 00088: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 784ms/step - loss: 0.0027 - binary_accuracy: 0.9990 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 89/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0027 - binary_accuracy: 0.9990\n",
            "Epoch 00089: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 779ms/step - loss: 0.0027 - binary_accuracy: 0.9990 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 90/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0020 - binary_accuracy: 0.9993\n",
            "Epoch 00090: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 790ms/step - loss: 0.0020 - binary_accuracy: 0.9993 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 91/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0028 - binary_accuracy: 0.9991\n",
            "Epoch 00091: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 788ms/step - loss: 0.0028 - binary_accuracy: 0.9991 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 92/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0028 - binary_accuracy: 0.9989\n",
            "Epoch 00092: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 792ms/step - loss: 0.0028 - binary_accuracy: 0.9989 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 93/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0020 - binary_accuracy: 0.9994\n",
            "Epoch 00093: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 780ms/step - loss: 0.0020 - binary_accuracy: 0.9994 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 94/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0026 - binary_accuracy: 0.9991\n",
            "Epoch 00094: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 61s 802ms/step - loss: 0.0026 - binary_accuracy: 0.9991 - val_loss: 0.0034 - val_binary_accuracy: 0.9990 - lr: 1.0000e-06\n",
            "Epoch 95/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0016 - binary_accuracy: 0.9994\n",
            "Epoch 00095: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 775ms/step - loss: 0.0016 - binary_accuracy: 0.9994 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-06\n",
            "Epoch 96/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0043 - binary_accuracy: 0.9986\n",
            "Epoch 00096: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 61s 799ms/step - loss: 0.0043 - binary_accuracy: 0.9986 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-06\n",
            "Epoch 97/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0027 - binary_accuracy: 0.9989\n",
            "Epoch 00097: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 789ms/step - loss: 0.0027 - binary_accuracy: 0.9989 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 98/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0016 - binary_accuracy: 0.9995\n",
            "Epoch 00098: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 796ms/step - loss: 0.0016 - binary_accuracy: 0.9995 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 99/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0018 - binary_accuracy: 0.9993\n",
            "Epoch 00099: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0018 - binary_accuracy: 0.9993 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 100/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0032 - binary_accuracy: 0.9991\n",
            "Epoch 00100: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0032 - binary_accuracy: 0.9991 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 101/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0026 - binary_accuracy: 0.9991\n",
            "Epoch 00101: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 782ms/step - loss: 0.0026 - binary_accuracy: 0.9991 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 102/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0018 - binary_accuracy: 0.9994\n",
            "Epoch 00102: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 58s 764ms/step - loss: 0.0018 - binary_accuracy: 0.9994 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 103/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0025 - binary_accuracy: 0.9992\n",
            "Epoch 00103: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 58s 770ms/step - loss: 0.0025 - binary_accuracy: 0.9992 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 104/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0022 - binary_accuracy: 0.9992\n",
            "Epoch 00104: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 785ms/step - loss: 0.0022 - binary_accuracy: 0.9992 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 105/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0031 - binary_accuracy: 0.9991\n",
            "Epoch 00105: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 792ms/step - loss: 0.0031 - binary_accuracy: 0.9991 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 106/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0027 - binary_accuracy: 0.9992\n",
            "Epoch 00106: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 783ms/step - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 107/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0036 - binary_accuracy: 0.9988\n",
            "Epoch 00107: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 59s 783ms/step - loss: 0.0036 - binary_accuracy: 0.9988 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 108/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0037 - binary_accuracy: 0.9987\n",
            "Epoch 00108: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 60s 793ms/step - loss: 0.0037 - binary_accuracy: 0.9987 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n",
            "Epoch 109/150\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.0029 - binary_accuracy: 0.9989\n",
            "Epoch 00109: val_loss did not improve from 0.00290\n",
            "76/76 [==============================] - 61s 799ms/step - loss: 0.0029 - binary_accuracy: 0.9989 - val_loss: 0.0034 - val_binary_accuracy: 0.9991 - lr: 1.0000e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUdqtmnIwA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7132f22-347c-45f3-b606-355f41a9a738"
      },
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks/mobilenetV2-train/mobile-netV2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/mobilenetV2-train/mobile-netV2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDYOaCHVXKlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "56ceff34-4491-45a1-a9a5-e99363a52eed"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auto-csv.py  predictor.py                training_utilities.py\n",
            "__init__.py  preprocessing_utilities.py  train.py\n",
            "models.py    \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}