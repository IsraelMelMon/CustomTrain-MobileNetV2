{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Isra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "10qbfEtglgTP3fe0tMLIknVk5fs-dFhUW",
      "authorship_tag": "ABX9TyNIOQ+QiVXGwYNwbhcb29xY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelMelMon/CustomTrain-MobileNetV2/blob/master/Isra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0X1u6MqxlHb"
      },
      "source": [
        "# Train your custom MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7g80Odcb8AP"
      },
      "source": [
        "See the original Github repository [here](https://github.com/IsraelMelMon/CustomTrain-MobileNetV2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2MsbU2Mx8JN"
      },
      "source": [
        "First, you must be signed-in to a [Google Drive](https://drive.google.com) account. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI7CoEBm5A6Y"
      },
      "source": [
        "Have a folder in your Google Drive named \"**mobilenet2/classes**\" that contains all the training images. \n",
        " >/content/drive/My Drive/mobilenet2/classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mak2DW605R2Z"
      },
      "source": [
        "Each class should be a sub-folder contained in the main training folder. \n",
        "An example with two classes is shown (although N different classes are supported):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTUrEGvk0z69"
      },
      "source": [
        "*/content/drive/My Drive/mobilenet2/*\n",
        "```sh\n",
        "├── mobilenet2\n",
        "  ├── example (can be downloaded from the Github)\n",
        "  ├── trainmobilenetv2 (can be downloaded from Github)\n",
        "  ├── classes\n",
        "    ├── class_A\n",
        "       ├── class_A_1.png\n",
        "       ├── class_A_2.png\n",
        "       ├── class_A_3.png\n",
        "       ├── ...\n",
        "       └── class_A_30.png\n",
        "    └── class_B\n",
        "        ├── class_B_1.png\n",
        "        ├── class_B_2.png\n",
        "        ├── class_B_3.png\n",
        "        ├── ...\n",
        "        └── class_B_30.png\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNYmE5eNaCpL"
      },
      "source": [
        "**Caution: Each image should contain the respective class' name**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQXCfwJ5chn"
      },
      "source": [
        "Next, we give Google Colab permission to access the files in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXR6TA_HCxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d9adf1-87dc-4aca-c341-ed8ad5380f43"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XgcnMvLAH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fdc5da-2554-46ac-eab8-63bb9ef21761"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDU5QO3K-0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583b2de4-f4d6-4cbb-bd73-70da0098b38e"
      },
      "source": [
        "!git clone https://github.com/IsraelMelMon/CustomTrain-MobileNetV2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CustomTrain-MobileNetV2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 90\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JRLSNiLEsk"
      },
      "source": [
        "cd CustomTrain-MobileNetV2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFi_NwK55rvq"
      },
      "source": [
        "Let's run the initial configuration file. The first argument is the absolute path to the training images folder, and the second argument is the number of epochs (default 50).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-8hY67Nxko5"
      },
      "source": [
        "!python3 '/content/CustomTrain-MobileNetV2/auto_setup.py' --path '/content/drive/MyDrive/DATASETS/HEB/TOP_10_CLASSES_JAN_27_2020/' "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJ966MdxcPv"
      },
      "source": [
        "Now we train our MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqbIBPp0kye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1134cd57-5b45-4ce3-d52f-f24a46ed7f1b"
      },
      "source": [
        "!python3 '/content/CustomTrain-MobileNetV2/scripts/train.py' --csv_path '/content/config_files/data.csv' --data_config_path '/content/config_files/data_config.yaml' --training_config_path '/content/config_files/training_config.yaml'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-28 05:32:56.194285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "['aguacate', 'limon', 'mango', 'manzana_golden', 'naranja']\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "2021-01-28 05:32:58.260049: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-28 05:32:58.261240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-28 05:32:58.272630: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-28 05:32:58.272692: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9e071569b67e): /proc/driver/nvidia/version does not exist\n",
            "2021-01-28 05:32:58.273220: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functiona (None, None, None, 1 2257984     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, None, 1 0           mobilenetv2_1.00_224[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 1280)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1280)         0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2560)         0           global_max_pooling2d[0][0]       \n",
            "                                                                 global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2560)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            12805       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,270,789\n",
            "Trainable params: 2,236,677\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2021-01-28 05:33:06.032198: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-01-28 05:33:06.032603: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/100\n",
            "   6/1064 [..............................] - ETA: 2:05:11 - loss: 3.7834 - binary_accuracy: 0.5082"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbnFEYbqgZyc"
      },
      "source": [
        "If the loss does not lower significantly (at least 1e-6) then the training automatically stops and saves the last weights together with the neural network as \"**mbnv2.h5**\" (by default, but can be manually modified by modifying the data_config.yaml and training_config.yaml file). This file can now be used for predictive inference."
      ]
    }
  ]
}